{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "750f684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------LIBRARIES--------------------------------------------------------------------------------------------\n",
    "import cv2                                                                                             #import OpenCV2 library for image processing and algorithms\n",
    "import math\n",
    "import numpy as np                                                                                     #import numpy mathematical library\n",
    "import pickle\n",
    "import operator                                                                                        #additional efficient pyhton fucntions \n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt      #import matplotlib library for plotting\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import ndimage                                                                              #package contains various functions for multidimensional image processing                       \n",
    "from webcolors import rgb_to_name, name_to_rgb                                                         #import the webcolors library which enables RGB to name and vice versa conversions\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                  #change width of Jupyer Notebook to use the whole window resolution available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dad324f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "\n",
      "Holes Found: 4 \n",
      "Area Found: 18609.0 \n",
      "Perimeter Found: 515.0437180995941 \n",
      "Ratio Found: 36.130913446849526 \n",
      "Corners Harris Method: 9 \n",
      "Corners Poly-Constant: 7 \n",
      "Corners Shi-Tomasi Method: 11 \n",
      "Lines Found: 39 \n",
      "Parallel Instances Found: 8 \n",
      "Circles Found: 0 \n",
      "Card Center X, Y: 258 172 \n",
      "Shape Height:  1.2170755389363523 \n",
      "Width Height:  0.821641687806771\n",
      "   0          1         2         3   4   5   6   7   8   9   10\n",
      "0   0  31.182488  1.435344  0.696697   1  11   2   1   5  13   7\n",
      "1   1  12.997193  2.232433  0.447942   1   5   0   0   6   8   6\n",
      "2   2  12.465836  1.346568  0.742629   1  10   0   1   7   2   8\n",
      "3   3  12.043974  1.390522  0.719154   1   7   0   1   8   1   8\n",
      "4   4  19.554152  1.419654  0.704397   1  17   6   0  12   6   5\n",
      "5   5  11.810718  1.463613  0.683241   1   6   0   1   8   6   8\n",
      "6   6  16.326844  8.169355  0.854427   1  11   2   1   7   3  10\n",
      "7   7  12.064693  1.478463  0.676378   1   8   0   0   7   2   5\n",
      "8   8  27.662455  1.524013  0.656162   2   5   0   2   2   2   6\n",
      "9   9  16.565916  8.230140  0.856950   1  12   0   1   7   1  10\n",
      "10  R  11.733160  3.615876  1.106397   1  10   2   0  15  20  14\n",
      "11  S  30.924468  1.155848  0.865165   2  17   2   0   4   4   8\n",
      "12  T  17.008548  3.526681  1.134756   2  12   0   0  12   4  10\n",
      "13  0  31.598795  1.428179  0.700192   1   7   2   0  28  33   8\n",
      "14  1  13.744383  2.228353  0.448762   1   5   0   0   9  10   5\n",
      "15  2  13.106539  1.362331  0.734036   1  11   2   1   7   1   9\n",
      "16  3  12.944200  1.385390  0.721818   1   7   0   1   5   1   7\n",
      "17  4  20.052873  1.397935  0.715341   1  13   4   0  13   7   5\n",
      "18  5  12.612310  1.464344  0.682900   1   7   0   1   9   2   8\n",
      "19  6  17.128294  8.036147  0.861994   1  12   0   1   7   1  10\n",
      "20  7  12.820399  1.475647  0.677669   1  10   0   0   7   1   6\n",
      "21  8  27.894646  1.518431  0.658574   2   7   0   2   2   2   6\n",
      "22  9  17.070896  7.603209  0.874039   1  11   0   1   6   2  13\n",
      "23  R  12.352779  3.564854  1.122142   1  10   2   0  13  17  12\n",
      "24  S  31.248653  1.153062  0.867256   2  15   6   0   4   4   8\n",
      "25  T  17.546260  3.467421  1.154113   2  11   0   0  10   6  10\n",
      "26  0  30.945938  1.439762  0.694559   1   8   0   1   3  18   8\n",
      "27  1  13.160243  2.225092  0.449420   1   7   0   0   7  13   6\n",
      "28  2  12.464924  1.334591  0.749293   1   9   0   1   6   2   8\n",
      "29  3  11.943662  1.384072  0.722506   1   7   0   1   7   1   8\n",
      "30  4  19.891051  1.397982  0.715317   1  13   2   0  15   7   6\n",
      "31  5  11.874283  1.465381  0.682416   1   8   0   1   8   2  10\n",
      "32  6  16.516580  8.406049  0.854592   1  13   0   1   8   1  11\n",
      "33  7  11.746147  1.486734  0.672615   1  14   2   0   6   1   6\n",
      "34  8  27.339357  1.524691  0.655871   2   9   0   2   2   2   6\n",
      "35  9  16.169306  8.749171  0.847335   1   8   0   1   7   2  10\n",
      "36  R  11.581615  3.654904  1.094564   1  11   2   0  13  26  14\n",
      "37  S  30.792476  1.159237  0.862636   2  17   2   0   4   4   7\n",
      "38  T  16.691597  3.520651  1.136436   2  14   4   0  14  10  10\n",
      "39  0  36.372793  1.369344  0.730277   1  30   6   1   2   4   8\n",
      "40  1  21.343106  2.059437  0.485570   1  13   4   0  14  21   6\n",
      "41  2  22.123106  1.479809  0.675763   3  31   4   1  14   9   8\n",
      "42  3  29.815061  1.479006  0.676130   3  31   4   1  21  26   7\n",
      "43  4  26.926198  1.352328  0.739466   2  27   2   0  26  18   5\n",
      "44  5  32.402514  1.480014  0.675669   2  19   2   1  17  14   6\n",
      "45  6  35.078150  1.689631  0.591845   4  43   4   1  21  19   5\n",
      "46  7  20.296730  1.599331  0.625261   1  21   2   0  12   7   6\n",
      "47  8  34.827799  1.400220  0.714173   4  37   6   2   9   9   6\n",
      "48  9  34.929888  1.695970  0.589633   3  40   2   1  20  19   5\n",
      "49  R  23.232157  2.580613  0.387505   3  26  10   0  30  41   4\n",
      "50  S  36.130913  1.217076  0.821642   4  39   8   0   9  11   7\n",
      "51  T  30.947913  1.822911  0.548573   5  20   2   0  12  12   6\n",
      "0     0\n",
      "1     1\n",
      "2     2\n",
      "3     3\n",
      "4     4\n",
      "5     5\n",
      "6     6\n",
      "7     7\n",
      "8     8\n",
      "9     9\n",
      "10    R\n",
      "11    S\n",
      "12    T\n",
      "13    0\n",
      "14    1\n",
      "15    2\n",
      "16    3\n",
      "17    4\n",
      "18    5\n",
      "19    6\n",
      "20    7\n",
      "21    8\n",
      "22    9\n",
      "23    R\n",
      "24    S\n",
      "25    T\n",
      "26    0\n",
      "27    1\n",
      "28    2\n",
      "29    3\n",
      "30    4\n",
      "31    5\n",
      "32    6\n",
      "33    7\n",
      "34    8\n",
      "35    9\n",
      "36    R\n",
      "37    S\n",
      "38    T\n",
      "39    0\n",
      "40    1\n",
      "41    2\n",
      "42    3\n",
      "43    4\n",
      "44    5\n",
      "45    6\n",
      "46    7\n",
      "47    8\n",
      "48    9\n",
      "49    R\n",
      "50    S\n",
      "51    T\n",
      "           1         2         3   4   5   6   7   8   9   10\n",
      "0   31.182488  1.435344  0.696697   1  11   2   1   5  13   7\n",
      "1   12.997193  2.232433  0.447942   1   5   0   0   6   8   6\n",
      "2   12.465836  1.346568  0.742629   1  10   0   1   7   2   8\n",
      "3   12.043974  1.390522  0.719154   1   7   0   1   8   1   8\n",
      "4   19.554152  1.419654  0.704397   1  17   6   0  12   6   5\n",
      "5   11.810718  1.463613  0.683241   1   6   0   1   8   6   8\n",
      "6   16.326844  8.169355  0.854427   1  11   2   1   7   3  10\n",
      "7   12.064693  1.478463  0.676378   1   8   0   0   7   2   5\n",
      "8   27.662455  1.524013  0.656162   2   5   0   2   2   2   6\n",
      "9   16.565916  8.230140  0.856950   1  12   0   1   7   1  10\n",
      "10  11.733160  3.615876  1.106397   1  10   2   0  15  20  14\n",
      "11  30.924468  1.155848  0.865165   2  17   2   0   4   4   8\n",
      "12  17.008548  3.526681  1.134756   2  12   0   0  12   4  10\n",
      "13  31.598795  1.428179  0.700192   1   7   2   0  28  33   8\n",
      "14  13.744383  2.228353  0.448762   1   5   0   0   9  10   5\n",
      "15  13.106539  1.362331  0.734036   1  11   2   1   7   1   9\n",
      "16  12.944200  1.385390  0.721818   1   7   0   1   5   1   7\n",
      "17  20.052873  1.397935  0.715341   1  13   4   0  13   7   5\n",
      "18  12.612310  1.464344  0.682900   1   7   0   1   9   2   8\n",
      "19  17.128294  8.036147  0.861994   1  12   0   1   7   1  10\n",
      "20  12.820399  1.475647  0.677669   1  10   0   0   7   1   6\n",
      "21  27.894646  1.518431  0.658574   2   7   0   2   2   2   6\n",
      "22  17.070896  7.603209  0.874039   1  11   0   1   6   2  13\n",
      "23  12.352779  3.564854  1.122142   1  10   2   0  13  17  12\n",
      "24  31.248653  1.153062  0.867256   2  15   6   0   4   4   8\n",
      "25  17.546260  3.467421  1.154113   2  11   0   0  10   6  10\n",
      "26  30.945938  1.439762  0.694559   1   8   0   1   3  18   8\n",
      "27  13.160243  2.225092  0.449420   1   7   0   0   7  13   6\n",
      "28  12.464924  1.334591  0.749293   1   9   0   1   6   2   8\n",
      "29  11.943662  1.384072  0.722506   1   7   0   1   7   1   8\n",
      "30  19.891051  1.397982  0.715317   1  13   2   0  15   7   6\n",
      "31  11.874283  1.465381  0.682416   1   8   0   1   8   2  10\n",
      "32  16.516580  8.406049  0.854592   1  13   0   1   8   1  11\n",
      "33  11.746147  1.486734  0.672615   1  14   2   0   6   1   6\n",
      "34  27.339357  1.524691  0.655871   2   9   0   2   2   2   6\n",
      "35  16.169306  8.749171  0.847335   1   8   0   1   7   2  10\n",
      "36  11.581615  3.654904  1.094564   1  11   2   0  13  26  14\n",
      "37  30.792476  1.159237  0.862636   2  17   2   0   4   4   7\n",
      "38  16.691597  3.520651  1.136436   2  14   4   0  14  10  10\n",
      "39  36.372793  1.369344  0.730277   1  30   6   1   2   4   8\n",
      "40  21.343106  2.059437  0.485570   1  13   4   0  14  21   6\n",
      "41  22.123106  1.479809  0.675763   3  31   4   1  14   9   8\n",
      "42  29.815061  1.479006  0.676130   3  31   4   1  21  26   7\n",
      "43  26.926198  1.352328  0.739466   2  27   2   0  26  18   5\n",
      "44  32.402514  1.480014  0.675669   2  19   2   1  17  14   6\n",
      "45  35.078150  1.689631  0.591845   4  43   4   1  21  19   5\n",
      "46  20.296730  1.599331  0.625261   1  21   2   0  12   7   6\n",
      "47  34.827799  1.400220  0.714173   4  37   6   2   9   9   6\n",
      "48  34.929888  1.695970  0.589633   3  40   2   1  20  19   5\n",
      "49  23.232157  2.580613  0.387505   3  26  10   0  30  41   4\n",
      "50  36.130913  1.217076  0.821642   4  39   8   0   9  11   7\n",
      "51  30.947913  1.822911  0.548573   5  20   2   0  12  12   6\n",
      "Score: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------DEFINITIONS-------------------------------------------------------------------------------------------\n",
    "def map_value(value, in_low, in_high, out_low, out_high):                                              #create Arduino map() function in python for usage throughout the code\n",
    "    return out_low + (out_high - out_low) * ((value - in_low) / (in_high - in_low))                    #scale input lowest,input highest range to output lowest,output highest range then return\n",
    "\n",
    "def to_bw(image):\n",
    "    output = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return output\n",
    "\n",
    "def rotate_img(img, angle):\n",
    "    result = ndimage.rotate(img, angle) \n",
    "    return result \n",
    "\n",
    "def find_contours(img_cnt, method):\n",
    "    img_cnt_bw = to_bw(img_cnt)                                                             #convert rescaled center image to black and white channels for post-processing\n",
    "    th_cnt_value, th_cnt_img = cv2.threshold(img_cnt_bw,127,255,cv2.THRESH_OTSU)                    #accurate countours, smoother edges compared to regular binary\n",
    "    kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "    morph_cnt_img = cv2.morphologyEx(th_cnt_img, cv2.MORPH_CLOSE, kernel_close)                       #erosion + dilute method (internal spaces removal)\n",
    "    canny_cnt_img = cv2.Canny(morph_cnt_img, 150, 500)  \n",
    "    \n",
    "    if method == \"EXTERNAL\":\n",
    "        contours_img_cnt, hierarchy_img_cnt = cv2.findContours(canny_cnt_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    elif method == \"TREE\":\n",
    "        contours_img_cnt, hierarchy_img_cnt = cv2.findContours(canny_cnt_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    return contours_img_cnt, hierarchy_img_cnt, canny_cnt_img\n",
    "\n",
    "def contour_removal_properties(image, min_corners, max_corners, min_ratio, max_ratio, min_height, max_height):\n",
    "    contours_found, __ = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    for c, cnt in enumerate(contours_found):                                                           # loop through all the found contours\n",
    "        perimeter, area, corners = contour_properties(cnt)\n",
    "        height, width = shape_height_width(cnt)\n",
    "        if not min_corners < corners < max_corners or min_ratio < area/perimeter < max_ratio or min_height < height < max_height:\n",
    "            contours_found.pop(c) \n",
    "    return contours_found\n",
    "\n",
    "def contour_removal_distance_centerpoints(contour_space, contour_space_center_x, contour_space_center_y, dist_min):\n",
    "    for i, cnt in enumerate(contour_space):\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        if ((((cx - contour_space_center_x)**2) + ((contour_space_center_y)**2))**0.5) > dist_min:\n",
    "            contours_space.pop(i)\n",
    "    return contour_space\n",
    "\n",
    "def draw_selected_contour(original, contour_space, contour, R,G,B, thickness):\n",
    "    drawn_contours_img = cv2.drawContours(original, contour_space[contour], -1, (R,G,B), thickness, cv2.LINE_AA)\n",
    "    return drawn_contours_img\n",
    "\n",
    "def yougest_children_img(img, contours_space_cnt, hierarchy_space_cnt):\n",
    "    hierarchy_space_cnt = hierarchy_space_cnt[0]\n",
    "    hierarchy_children_img = img.copy()\n",
    "    children_found = 0\n",
    "    for component in zip(contours_space_cnt, hierarchy_space_cnt):\n",
    "        currentContour = component[0]\n",
    "        currentHierarchy = component[1]\n",
    "        x,y,w,h = cv2.boundingRect(currentContour)\n",
    "        if currentHierarchy[2] < 0:                                                                       # these are the innermost child components\n",
    "            cv2.rectangle(hierarchy_children_img ,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "            children_found += 1\n",
    "    return int(children_found/3), hierarchy_children_img\n",
    "\n",
    "def find_center(image):\n",
    "    contour_bw = to_bw(image)                                                              #convert rescaled center image to black and white channels for post-processing\n",
    "    thr_value2, th_shape_img = cv2.threshold(contour_bw,127,255,cv2.THRESH_OTSU)                    #accurate countours, smoother edges compared to regular binary\n",
    "    kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "    morph_shape_img = cv2.morphologyEx(th_shape_img , cv2.MORPH_CLOSE, kernel_close)                       #erosion + dilute method (internal spaces removal)\n",
    "    canny_shape_img = cv2.Canny(morph_shape_img, 150, 500)  \n",
    "    contours_shape, hierarchy_shape = cv2.findContours(canny_shape_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "    center_identified_img = image.copy()\n",
    "    M = cv2.moments(contours_shape[1])\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.circle(center_identified_img, (cx, cy), 7, (0, 0, 255), -1)\n",
    "        cv2.putText(center_identified_img, \"CENTER\", (cx - 30, cy - 10),\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    return center_identified_img, cx, cy\n",
    "\n",
    "def contour_extraction(image, contours_space, cnt):\n",
    "    mask = np.zeros_like(image) # Create mask where white is what we want, black otherwise\n",
    "    cv2.drawContours(mask, contours_space, cnt, 255, -1) # Draw filled contour in mask\n",
    "    masked = np.zeros_like(image) # Extract out the object and place into output image\n",
    "    masked[mask == 255] = image[mask == 255]\n",
    "    return masked\n",
    "\n",
    "def contour_bound_crop(img, cnts, cnt):\n",
    "    [x,y,w,h] = cv2.boundingRect(cnts[cnt])\n",
    "    box = cv2.rectangle(img.copy(), (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "    cropped = img[y-10:y+h+10, x-10:x+w+10]\n",
    "    return cropped, box\n",
    "\n",
    "def sharpen_image(image, sharpness, threshold):\n",
    "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, (5,5) , 1.0)\n",
    "    sharpened = float(sharpness + 1) * image - float(sharpness) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "def contour_properties(contour_selected, req):\n",
    "    perimeter = cv2.arcLength(contour_selected, True)                                                                    # perimeter of contour c (curved length)     \n",
    "    area = cv2.contourArea(contour_selected)                                                                     \n",
    "    corners = len(cv2.approxPolyDP(contour_selected, 0.04*perimeter, True))\n",
    "    if req == \"A\":\n",
    "        return area\n",
    "    elif req == \"P\":\n",
    "        return perimeter\n",
    "    elif req == \"C\":\n",
    "        return corners\n",
    "\n",
    "def shape_ratio(perimeter, area):\n",
    "    ratio = area/perimeter   \n",
    "    return ratio\n",
    "\n",
    "def fit_ellipse(contour_selected):\n",
    "    ellipse_found = cv2.fitEllipse(contour_selected)                                                                      # fit an ellipse on the contour\n",
    "    (center, axes, orientation) = ellipse_found                                                            # extract the main parameter\n",
    "    majoraxis_length = max(axes)                              \n",
    "    minoraxis_length = min(axes)\n",
    "    return minoraxis_length, majoraxis_length\n",
    "\n",
    "def shape_height_width(contour_selected, val):\n",
    "    minor, major = fit_ellipse(contour_selected)\n",
    "    height = major/minor\n",
    "    width = minor/major\n",
    "    if val == \"H\":\n",
    "        return height\n",
    "    if val == \"W\":\n",
    "        return width\n",
    "\n",
    "def contour_masking(morphology, cnts, selected):\n",
    "    mask = np.zeros_like(morphology)                                                               # Create mask where white is what we want, black otherwise\n",
    "    cv2.drawContours(mask, cnts, selected, 255, -1)                                       # Draw filled contour in mask\n",
    "    masked = np.zeros_like(morphology)                                                              #Extract out the object and place into output image\n",
    "    masked[mask == 255] = morphology[mask == 255]\n",
    "    return masked\n",
    "\n",
    "def harris_method_corners(image):\n",
    "    harris_method_BGR_img= image.copy()\n",
    "    harris_method_bw_img = np.float32(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "    dst = cv2.cornerHarris(harris_method_bw_img,5,3,0.04)\n",
    "    ret, dst = cv2.threshold(dst,0.1*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    harris_corners = cv2.cornerSubPix(harris_method_bw_img,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "    harris_method_BGR_img[dst>0.1*dst.max()]=[0,0,255]   \n",
    "    \n",
    "    for c in range(1, len(harris_corners)):\n",
    "        cv2.circle(harris_method_BGR_img, (int(harris_corners[c,0]), int(harris_corners[c,1])), 7, (0,255,0), 2)\n",
    "    \n",
    "    return c, harris_method_BGR_img\n",
    "\n",
    "def shi_tomasi_method_corners(image):\n",
    "    shi_tomasi_BGR_img= image.copy()\n",
    "    shi_tomasi_method_bw_img = cv2.cvtColor(shi_tomasi_BGR_img, cv2.COLOR_BGR2GRAY)\n",
    "    shi_tomasi_corners = cv2.goodFeaturesToTrack(shi_tomasi_method_bw_img, 0, 0.25, 0.05)\n",
    "    shi_tomasi_corners = np.int0(shi_tomasi_corners)\n",
    "                                                                                                  \n",
    "    for i in shi_tomasi_corners:                                                                                    # draw red color circles on all corners\n",
    "        x, y = i.ravel()\n",
    "        cv2.circle(shi_tomasi_BGR_img, (x, y), 3, (0, 0, 255), -1)\n",
    "    return len(shi_tomasi_corners), shi_tomasi_BGR_img\n",
    "\n",
    "def houghcircles(image, min_radius, max_radius, circle_dist):\n",
    "    circles_count = 0   \n",
    "    houghcircles_BGR_img= image.copy()\n",
    "    houghcircles_bw_img = cv2.cvtColor(houghcircles_BGR_img, cv2.COLOR_BGR2GRAY)\n",
    "    rows = houghcircles_bw_img.shape[0]\n",
    "    circles = cv2.HoughCircles(houghcircles_bw_img, cv2.HOUGH_GRADIENT, 1, rows / circle_dist,\n",
    "                               param1=100, param2=30, minRadius=min_radius, maxRadius=max_radius)\n",
    "        \n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])           \n",
    "            cv2.circle(houghcircles_BGR_img, center, 1, (0, 100, 100), 3)                           # circle center           \n",
    "            radius = i[2]                                                                              # circle outline\n",
    "            cv2.circle(houghcircles_BGR_img, center, radius, (255, 0, 255), 3)\n",
    "        circles_count = int(circles.size/3)\n",
    "    return circles_count, houghcircles_BGR_img\n",
    "\n",
    "def houghlines(image, canny_edges):\n",
    "    lines_img = image.copy()\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 10  # angular resolution in radians of the Hough grid\n",
    "    threshold = 17 # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15  # minimum number of pixels making up a line\n",
    "    max_line_gap = 18 # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(image) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(canny_edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    line_counter = 0\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            line_counter += 1\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),5)\n",
    "\n",
    "    lines_edges = cv2.addWeighted(lines_img, 1, line_image, 1, 0)\n",
    "    \n",
    "    parallel = []\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines)):\n",
    "            if (i == j):continue\n",
    "            if (abs(lines[i][0][1] - lines[j][0][1]) == 0):         \n",
    "                parallel.append((i,j))\n",
    "    return line_counter, lines_edges, len(parallel)\n",
    "    \n",
    "    \n",
    "#----------------------------------------------------------------------------------------IMAGE PRE-PROCESSING---------------------------------------------------------------------------------------\n",
    "image_filename = './uno_images/ys.jpg'\n",
    "card_type = image_filename[-5:-4]\n",
    "print(card_type)\n",
    "input_img = cv2.imread(image_filename)                                                         #load the image from the specified path\n",
    "rotated_img = rotate_img(input_img, -90)                                                          #rotate image by 90 degrees, increase user ease of use\n",
    "rotated_img_copy = rotated_img.copy()                                                                  #create a copy of the rotated_img so that they don't share the same memory address\n",
    "bw_img = to_bw(rotated_img_copy)                                                 #convert to a black and white image\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------POST-PROCESSING-----------------------------------------------------------------------------------------\n",
    "thr_value, th_img = cv2.threshold(bw_img,150, 400, cv2.THRESH_BINARY_INV)                              #accurate countours, smoother edges compared to regular binary\n",
    "kernel = np.ones((3, 3), np.uint8)                                                                     #higher kernel = less accurate contours\n",
    "#close_img = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)                                         #erosion + dilute method (internal spaces removal)\n",
    "open_img = cv2.morphologyEx(th_img, cv2.MORPH_OPEN, kernel)                                            #dilute + erosion method (noise removal)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------EDGE DETENCTION & CONTOUR MAPPING---------------------------------------------------------------------------------\n",
    "canny_img = cv2.Canny(open_img, 50, 100)                                                               #edge detection using the OpenCV Canny method\n",
    "contours, _ = cv2.findContours(open_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  \n",
    "selected_contour = 1                                                                                   #0 = frame; 1 = uno card perimeter; \n",
    "contours_img = draw_selected_contour(rotated_img, contours, selected_contour, 0,255,0, 2)              #draw selected contour on top of the rotated colour image\n",
    "#print(len(contours))                                                                                  #debugging: show how many contours have been found\n",
    "#print(hierarchy)                                                                                      #debugging: show hierarchy list for all contours\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------OPEN CV CONTOUR CROPPING USING CONTOURS FUNCTION--------------------------------------------------------------------------- \n",
    "x_cnt,y_cnt,w_cnt,h_cnt = cv2.boundingRect(contours[selected_contour])                                 #find origin, width and heigth of image based on selected_contour\n",
    "contour_cropped_proc_img = rotated_img_copy[y_cnt-5:y_cnt+h_cnt+5, x_cnt-5:x_cnt+w_cnt+5]                            #crop the image based on the coordinates found for processing\n",
    "framed_img = cv2.copyMakeBorder(contour_cropped_proc_img,                                              #add a 30px wide black frame around the cropped image (helps with text placement) \n",
    "                                30,30,30,30,\n",
    "                                cv2.BORDER_CONSTANT,\n",
    "                                value=(0,0,0)) \n",
    "#print(x_cnt, y_cnt, w_cnt, h_cnt)                                                                     #print 4 values for debugging\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------COLOUR ANALYSIS--------------------------------------------------------------------------------------------\n",
    "contour_cropped_analysis_img = rotated_img_copy[y_cnt-5:y_cnt+h_cnt+5, x_cnt-5:x_cnt+w_cnt+5]                  #crop the rotated original image copy with the uno card contour for pattern/colour processing\n",
    "#a patch of pixels is chosen to increase accuracy \n",
    "#as well as optimise the code by running through less pixels in the functions to follow\n",
    "colour_patch_img = contour_cropped_analysis_img[40:80, 100:140]                                        #select a constant patch from the uno card image to perform the pixel analysis\n",
    "bgr_pixels = colour_patch_img.tolist()                                                                 #transform patch array to list containing bgr tuples\n",
    "#print(bgr_pixels)\n",
    "b = [x[0][0] for x in bgr_pixels]                                                                      #extract blue values from bgr list\n",
    "g = [x[0][1] for x in bgr_pixels]                                                                      #extract green values from bgr list\n",
    "r = [x[0][2] for x in bgr_pixels]                                                                      #extract red values from bgr list\n",
    "frequent_b = (max(set(b), key = b.count))                                                              #find the most frequent blue value in the image patch selected\n",
    "frequent_g = (max(set(g), key = g.count))                                                              #find the most frequent green value in the image patch selected\n",
    "frequent_r = (max(set(r), key = r.count))                                                              #find the most frequent red value in the image patch selected\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------COLOUR IDENTIFICATION------------------------------------------------------------------------------------------    \n",
    "rgb_dictionary = {\"red\": frequent_r, \"green\": frequent_g, \"blue\": frequent_b}                          #create dictionary containing the RGB colour space, and assign most frequent value from patch\n",
    "sorted_rgb_dictionary = dict((y, x) for y, x in sorted(rgb_dictionary.items(),                         #sort dictionary based on value, not key and since the output is a tuple, transform to dictionary\n",
    "                                                       key=operator.itemgetter(1)))                    #choose value for sorting process, (1) = value, (0) = key\n",
    "highest_rgb_value = list(sorted_rgb_dictionary)[2]                                                     #extract highest value whether it is a blue, green or red pixel (key)\n",
    "middle_rgb_value = list(sorted_rgb_dictionary)[1]                                                      #extract middle value whether it is a blue, green or red pixel (key)\n",
    "lowest_rgb_value = list(sorted_rgb_dictionary)[0]                                                      #extract lowest value whether it is a blue, green or red pixel (key)\n",
    "\n",
    "#the following part of the code changes the R,G,B values of the pixels to an extreme\n",
    "#this helps identify the colour correctly with different levels of brightness in the image\n",
    "colour_rgb = [0,0,0]                                                                                   #create list to store the new RGB values for colour identification\n",
    "if sorted_rgb_dictionary.get(highest_rgb_value) >= 255/2:                                              #if the highest pixel value is higher than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "elif sorted_rgb_dictionary.get(highest_rgb_value) <= 255/2:                                            #if the highest pixel value is lower than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 128                                                                                #assign the first element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 128                                                                                #assign the second element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 128                                                                                #assign the third element in the colour_rgb = 128 \n",
    "if sorted_rgb_dictionary.get(middle_rgb_value) > 150:                                                  #if the middle pixel value is higher than 150, then:\n",
    "    if middle_rgb_value == \"red\":                                                                      #if the middle_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"green\":                                                                  #if the middle_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"blue\":                                                                   #if the middle_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "if sorted_rgb_dictionary.get(lowest_rgb_value) < 255/2:                                                #if the lowest pixel value is lower than the mid-point, then:\n",
    "    if lowest_rgb_value == \"red\":                                                                      #if the lowest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 0                                                                                  #assign the first element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"green\":                                                                  #if the lowest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 0                                                                                  #assign the second element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"blue\":                                                                   #if the lowest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 0 \n",
    "\n",
    "named_colour = rgb_to_name(colour_rgb)                                                                 #use webcolours library database to convert RGB to HEX and then to colour name in English \n",
    "colour_framed_img = cv2.copyMakeBorder(framed_img,7,7,7,7,cv2.BORDER_CONSTANT,                         #add a 7px wide frame at the edge of the frame with the same colour as the UNO card\n",
    "                                       value=(colour_rgb[2],colour_rgb[1],colour_rgb[0]))              #elements 2,1,0 used because of BGR output, and RGB input\n",
    "\"\"\"\n",
    "#Debugging\n",
    "test = name_to_rgb('cyan') \n",
    "print(test)\n",
    "print(sorted_rgb_dictionary)\n",
    "print(type(highest_rgb_value))\n",
    "print(lowest_rgb_value, middle_rgb_value, highest_rgb_value)\n",
    "print(colour, named_colour)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------CONTOUR CROPPED SCALING-----------------------------------------------------------------------------------------\n",
    "contour_cropped = contour_cropped_analysis_img.copy()   \n",
    "scale_percent = 200 # percent of original size\n",
    "dim =  (int(contour_cropped.shape[1] * scale_percent / 100), int(contour_cropped.shape[0] * scale_percent / 100))\n",
    "contour_cropped_resized = cv2.resize(contour_cropped, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------CONTOUR CROPPED SHARPENING----------------------------------------------------------------------------------------\n",
    "contour_cropped_sharpened = sharpen_image(contour_cropped_resized, 0.22, 0)\n",
    "kernel_size = 5\n",
    "contour_cropped_blurred = cv2.GaussianBlur(contour_cropped_resized,(kernel_size, kernel_size),0)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------CONTOUR CENTER-----------------------------------------------------------------------------------------------------\n",
    "center_img, center_x, center_y = find_center(contour_cropped_sharpened)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "ellipse_cropped = contour_cropped_blurred.copy()\n",
    "mask = np.zeros_like(ellipse_cropped)\n",
    "rows, cols,_ = mask.shape\n",
    "center_x=int(rows/2)\n",
    "center_y=int(cols/2)\n",
    "center = (center_y,center_x)\n",
    "\n",
    "mask = cv2.ellipse(mask, center, axes=(95, 160), angle=25, startAngle=0, endAngle = 360, color=(255,255,255), thickness = -1)\n",
    "ellipse_masked_img = np.bitwise_and(ellipse_cropped, mask)\n",
    "ellipse_masked_img[np.all(ellipse_masked_img == (0, 0, 0), axis=-1)] = (frequent_b, frequent_g, frequent_r)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------CENTER CROPPED POST-PROCESSING---------------------------------------------------------------------------------------\n",
    "contours_uno, hierarchy_uno, canny_uno_img = find_contours(contour_cropped_resized, \"TREE\")\n",
    "contours_center, hierarchy_center, canny_center_img = find_contours(ellipse_masked_img, \"EXTERNAL\")\n",
    "\n",
    "contours_final = list()\n",
    "hierarchy_center = hierarchy_center[0]\n",
    "cut = 0\n",
    "for component in zip(contours_center, hierarchy_center):\n",
    "    currentContour = component[0]\n",
    "    currentHierarchy = component[1]\n",
    "    if currentHierarchy[2] < 0:\n",
    "        contours_final.append(currentContour)\n",
    "        cut += 1\n",
    "\n",
    "#-------------------------------------------------------------------------------------FEATURE SPACE RECOGNITION----------------------------------------------------------------------------------------\n",
    "#defining all features\n",
    "height_found, width_found, area_found, perimeter_found, poly_corners_found = 0,0,0,0,0\n",
    "for i in range(len(contours_final)):\n",
    "    drawn_contour_img = draw_selected_contour(ellipse_masked_img.copy(), contours_final, i, 0,255,0, 2)\n",
    "    area_found += contour_properties(contours_final[i], \"A\")\n",
    "    perimeter_found += contour_properties(contours_final[i], \"P\")\n",
    "    poly_corners_found += contour_properties(contours_final[i], \"C\")\n",
    "    height_found += shape_height_width(contours_final[i], \"H\") \n",
    "    width_found += shape_height_width(contours_final[i], \"W\") \n",
    "\n",
    "ratio_found = shape_ratio(perimeter_found, area_found)    \n",
    "harris_corners, harris_corners_img = harris_method_corners(ellipse_masked_img)\n",
    "shi_tomasi_corners, shi_tomasi_img = shi_tomasi_method_corners(ellipse_masked_img)\n",
    "lines_found, lines_found_image, parallel_instances_found = houghlines(ellipse_masked_img, canny_center_img)\n",
    "circles_found, houghcircles_img = houghcircles(ellipse_masked_img, 15, 30, 8)\n",
    "children_found_counter, children_found_img = yougest_children_img(contour_cropped_resized, contours_uno, hierarchy_uno)\n",
    "\n",
    "features = [card_type, ratio_found, height_found, width_found, children_found_counter, lines_found, parallel_instances_found, circles_found, harris_corners, shi_tomasi_corners, poly_corners_found]\n",
    "#Debugging\n",
    "print('\\nHoles Found:', children_found_counter,\n",
    "      '\\nArea Found:', area_found,\n",
    "      '\\nPerimeter Found:', perimeter_found,\n",
    "      '\\nRatio Found:', ratio_found,\n",
    "      '\\nCorners Harris Method:', harris_corners,\n",
    "      '\\nCorners Poly-Constant:', poly_corners_found,\n",
    "      '\\nCorners Shi-Tomasi Method:', shi_tomasi_corners,\n",
    "      '\\nLines Found:', lines_found,\n",
    "      '\\nParallel Instances Found:', parallel_instances_found,\n",
    "      '\\nCircles Found:', circles_found,\n",
    "      '\\nCard Center X, Y:', center_x, center_y,\n",
    "      '\\nShape Height: ', height_found,\n",
    "      '\\nWidth Height: ', width_found)\n",
    "\n",
    "\"\"\"\n",
    "cv2.imshow('shi_tomasi_img',shi_tomasi_img)\n",
    "cv2.imshow('harris_corners', harris_corners_img)\n",
    "cv2.imshow('houghcircles_img', houghcircles_img)\n",
    "cv2.imshow('contour_cropped', contour_cropped)\n",
    "cv2.imshow('sharpened_img', contour_cropped_sharpened)\n",
    "cv2.imshow('children_found_img', children_found_img)\n",
    "cv2.imshow('morph_center_img' , morph_center_img)\n",
    "cv2.imshow('lines_found_image', lines_found_image)\n",
    "cv2.imshow('ellipse_masked_img', ellipse_masked_img)\n",
    "cv2.imshow('drawn_contour_img', drawn_contour_img)\n",
    "cv2.imshow('center_img', center_img)\n",
    "cv2.imshow('canny_center_img', canny_center_img)\n",
    "\n",
    "#------------------------------------------------------------------------------------IDENTIFICATION TEXT PLACEMENT--------------------------------------------------------------------------------------                                                                      \n",
    "disp_x = +240                                                                                          #perfect value = +240\n",
    "disp_y = -165                                                                                          #perfect value = -165\n",
    "text_displayed = (named_colour + \" \" + \" uno card\").upper()\n",
    "identified_img = cv2.putText(colour_framed_img,                                                        #create text on top of image\n",
    "                             text_displayed,                                                           #set text to text_displayed string\n",
    "                             (y_cnt+disp_y, x_cnt+disp_x),                                             #set coords to contour bottom right corner with displacement\n",
    "                             cv2.FONT_HERSHEY_SIMPLEX,                                                 #set OpenCV font\n",
    "                             0.4, (0,255,0), 1, cv2.LINE_AA)                                           #font size, colour, thickness, antialiasing on the text for smoother edges\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------POST-PROCESSED IMAGE SCALLING-------------------------------------------------------------------------------------                                                                                             \n",
    "scaling = int(identified_img.shape[1]*1.5),int(identified_img.shape[0]*1.5)                            #scale the output image by 1.5x\n",
    "final_img = cv2.resize(identified_img, scaling, interpolation = cv2.INTER_AREA)                        #scale the identified_img, with scaling resolution\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------IMAGE DISPLAY---------------------------------------------------------------------------------------------- \n",
    "cv2.imshow('original', input_img)                                                                     #show the original image to the user\n",
    "cv2.imshow('final_img', final_img)                                                                     #show the final image to the user    \n",
    "\n",
    "key = cv2.waitKey(0)                                                                                   #wait for any key press\n",
    "cv2.destroyAllWindows()                                                                                #close all windows displaying images\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------------------MACHINE LEARNING MODEL-----------------------------------------------------------------------------------------  \n",
    "#dataset = np.loadtxt('datset.csv')                                                                    #doesn't work with numpy load as the file contains different type elements\n",
    "dataset = pd.read_csv('./dataset.csv', header=None)\n",
    "print(dataset.to_string())\n",
    "\n",
    "X = dataset.iloc[:, 1:]                                                                                 #feature space matrix\n",
    "y = dataset.iloc[:, 0]                                                                                  #label fector\n",
    "print(y.to_string())\n",
    "print(X.to_string())\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test) # predict and calculate the classification accuracy\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e828e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
