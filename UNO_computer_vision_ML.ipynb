{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "750f684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------LIBRARIES--------------------------------------------------------------------------------------------\n",
    "import cv2                                                                                             #import OpenCV2 library for image processing and algorithms\n",
    "import math\n",
    "import numpy as np                                                                                     #import numpy mathematical library\n",
    "import operator                                                                                        #additional efficient pyhton fucntions \n",
    "import matplotlib.pyplot as plt                                                                        #import matplotlib library for plotting\n",
    "from scipy import ndimage                                                                              #package contains various functions for multidimensional image processing                       \n",
    "from webcolors import rgb_to_name, name_to_rgb                                                         #import the webcolors library which enables RGB to name and vice versa conversions\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                  #change width of Jupyer Notebook to use the whole window resolution available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 22\n",
      "<class 'list'> 21\n",
      "<class 'list'> 20\n",
      "<class 'list'> 20\n",
      "<class 'list'> 20\n",
      "<class 'list'> 20\n",
      "<class 'list'> 20\n",
      "<class 'list'> 19\n",
      "<class 'list'> 18\n",
      "<class 'list'> 17\n",
      "<class 'list'> 17\n",
      "<class 'list'> 17\n",
      "<class 'list'> 16\n",
      "<class 'list'> 16\n",
      "<class 'list'> 16\n",
      "<class 'list'> 16\n",
      "<class 'list'> 16\n",
      "6.615596896100087 4\n",
      "Tallness:  6.899001018227238\n",
      "Harris corners:  12\n",
      "Shi-Tomasi Corners Detected:  [[[108 298]]\n",
      "\n",
      " [[190 299]]\n",
      "\n",
      " [[153 299]]\n",
      "\n",
      " [[135 299]]\n",
      "\n",
      " [[106 296]]\n",
      "\n",
      " [[190 286]]\n",
      "\n",
      " [[107 286]]]\n",
      "<class 'NoneType'> None\n"
     ]
    }
   ],
   "source": [
    "###### --------------------------------------------------------------------------------------------DEFINITIONS-------------------------------------------------------------------------------------------\n",
    "def map_value(value, in_low, in_high, out_low, out_high):                                              #create Arduino map() function in python for usage throughout the code\n",
    "    return out_low + (out_high - out_low) * ((value - in_low) / (in_high - in_low))                    #scale input lowest,input highest range to output lowest,output highest range then return\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------IMAGE PRE-PROCESSING---------------------------------------------------------------------------------------\n",
    "colour_img = cv2.imread('./uno_images/b9.jpg')                                                         #load the image from the specified path\n",
    "rotated_img = ndimage.rotate(colour_img, -90)                                                          #rotate image by 90 degrees, increase user ease of use\n",
    "rotated_img_copy = rotated_img.copy()                                                                  #create a copy of the rotated_img so that they don't share the same memory address\n",
    "bw_img = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2GRAY)                                                 #convert to a black and white image\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------POST-PROCESSING-----------------------------------------------------------------------------------------\n",
    "thr_value, th_img = cv2.threshold(bw_img,150, 400, cv2.THRESH_BINARY_INV)                              #accurate countours, smoother edges compared to regular binary\n",
    "#very small changes with images provided, helps with countour accuracy\n",
    "kernel = np.ones((3, 3), np.uint8)                                                                     #higher kernel = less accurate contours\n",
    "#close_img = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)                                         #erosion + dilute method (internal spaces removal)\n",
    "open_img = cv2.morphologyEx(th_img, cv2.MORPH_OPEN, kernel)                                            #dilute + erosion method (noise removal)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------EDGE DETENCTION & CONTOUR MAPPING---------------------------------------------------------------------------------\n",
    "canny_img = cv2.Canny(open_img, 50, 100)                                                               #edge detection using the OpenCV Canny method\n",
    "contours, _ = cv2.findContours(open_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  \n",
    "selected_contour = 1                                                                                   #0 = frame; 1 = uno card perimeter;\n",
    "contours_img = cv2.drawContours(rotated_img, contours, selected_contour, (0,255,0), 2, cv2.LINE_AA)    #draw selected contour on top of the rotated colour image\n",
    "#print(len(contours))                                                                                  #debugging: show how many contours have been found\n",
    "#print(hierarchy)                                                                                      #debugging: show hierarchy list for all contours\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------OPEN CV CONTOUR CROPPING USING CONTOURS FUNCTION--------------------------------------------------------------------------- \n",
    "x_cnt,y_cnt,w_cnt,h_cnt = cv2.boundingRect(contours[selected_contour])                                 #find origin, width and heigth of image based on selected_contour\n",
    "contour_cropped_proc_img = rotated_img[y_cnt:y_cnt+h_cnt, x_cnt:x_cnt+w_cnt]                           #crop the image based on the coordinates found for processing\n",
    "framed_img = cv2.copyMakeBorder(contour_cropped_proc_img,                                              #add a 30px wide black frame around the cropped image (helps with text placement) \n",
    "                                30,30,30,30,\n",
    "                                cv2.BORDER_CONSTANT,\n",
    "                                value=(0,0,0)) \n",
    "#print(x_cnt, y_cnt, w_cnt, h_cnt)                                                                     #print 4 values for debugging\n",
    " \n",
    "\n",
    "#-------------------------------------------------------------------------------------------COLOUR ANALYSIS--------------------------------------------------------------------------------------------\n",
    "contour_cropped_analysis_img = rotated_img_copy[y_cnt:y_cnt+h_cnt, x_cnt:x_cnt+w_cnt]                  #crop the rotated original image copy with the uno card contour for pattern/colour processing\n",
    "#a patch of pixels is chosen to increase accuracy \n",
    "#as well as optimise the code by running through less pixels in the functions to follow\n",
    "colour_patch_img = contour_cropped_analysis_img[40:80, 100:140]                                        #select a constant patch from the uno card image to perform the pixel analysis\n",
    "bgr_pixels = colour_patch_img.tolist()                                                                 #transform patch array to list containing bgr tuples\n",
    "#print(bgr_pixels)\n",
    "b = [x[0][0] for x in bgr_pixels]                                                                      #extract blue values from bgr list\n",
    "g = [x[0][1] for x in bgr_pixels]                                                                      #extract green values from bgr list\n",
    "r = [x[0][2] for x in bgr_pixels]                                                                      #extract red values from bgr list\n",
    "frequent_b = (max(set(b), key = b.count))                                                              #find the most frequent blue value in the image patch selected\n",
    "frequent_g = (max(set(g), key = g.count))                                                              #find the most frequent green value in the image patch selected\n",
    "frequent_r = (max(set(r), key = r.count))                                                              #find the most frequent red value in the image patch selected\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------COLOUR IDENTIFICATION------------------------------------------------------------------------------------------    \n",
    "rgb_dictionary = {\"red\": frequent_r, \"green\": frequent_g, \"blue\": frequent_b}                          #create dictionary containing the RGB colour space, and assign most frequent value from patch\n",
    "sorted_rgb_dictionary = dict((y, x) for y, x in sorted(rgb_dictionary.items(),                         #sort dictionary based on value, not key and since the output is a tuple, transform to dictionary\n",
    "                                                       key=operator.itemgetter(1)))                    #choose value for sorting process, (1) = value, (0) = key\n",
    "highest_rgb_value = list(sorted_rgb_dictionary)[2]                                                     #extract highest value whether it is a blue, green or red pixel (key)\n",
    "middle_rgb_value = list(sorted_rgb_dictionary)[1]                                                      #extract middle value whether it is a blue, green or red pixel (key)\n",
    "lowest_rgb_value = list(sorted_rgb_dictionary)[0]                                                      #extract lowest value whether it is a blue, green or red pixel (key)\n",
    "\n",
    "#the following part of the code changes the R,G,B values of the pixels to an extreme\n",
    "#this helps identify the colour correctly with different levels of brightness in the image\n",
    "colour_rgb = [0,0,0]                                                                                   #create list to store the new RGB values for colour identification\n",
    "if sorted_rgb_dictionary.get(highest_rgb_value) >= 255/2:                                              #if the highest pixel value is higher than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "elif sorted_rgb_dictionary.get(highest_rgb_value) <= 255/2:                                            #if the highest pixel value is lower than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 128                                                                                #assign the first element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 128                                                                                #assign the second element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 128                                                                                #assign the third element in the colour_rgb = 128 \n",
    "if sorted_rgb_dictionary.get(middle_rgb_value) > 150:                                                  #if the middle pixel value is higher than 150, then:\n",
    "    if middle_rgb_value == \"red\":                                                                      #if the middle_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"green\":                                                                  #if the middle_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"blue\":                                                                   #if the middle_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "if sorted_rgb_dictionary.get(lowest_rgb_value) < 255/2:                                                #if the lowest pixel value is lower than the mid-point, then:\n",
    "    if lowest_rgb_value == \"red\":                                                                      #if the lowest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 0                                                                                  #assign the first element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"green\":                                                                  #if the lowest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 0                                                                                  #assign the second element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"blue\":                                                                   #if the lowest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 0 \n",
    "        \n",
    "named_colour = rgb_to_name(colour_rgb)                                                                 #use webcolours library database to convert RGB to HEX and then to colour name in English \n",
    "colour_framed_img = cv2.copyMakeBorder(framed_img,7,7,7,7,cv2.BORDER_CONSTANT,                         #add a 7px wide frame at the edge of the frame with the same colour as the UNO card\n",
    "                                       value=(colour_rgb[2],colour_rgb[1],colour_rgb[0]))              #elements 2,1,0 used because of BGR output, and RGB input\n",
    "\"\"\"\n",
    "#Debugging\n",
    "test = name_to_rgb('cyan') \n",
    "print(test)\n",
    "print(sorted_rgb_dictionary)\n",
    "print(type(highest_rgb_value))\n",
    "print(lowest_rgb_value, middle_rgb_value, highest_rgb_value)\n",
    "print(colour, named_colour)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------RESOLUTION NORMALIZATION------------------------------------------------------------------------------------------\n",
    "contour_cropped_copy = contour_cropped_analysis_img.copy()                                             #create a copy of the uno card contour cropped image\n",
    "normalize_resolution = (300, 450)                                                                      #have a set resolution between all images (after cropping)\n",
    "normalized_img = cv2.resize(contour_cropped_copy, normalize_resolution,                                #set image to be resized and the resolution\n",
    "                                        interpolation = cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow('normalized', normalized_img)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------SHAPE IMAGE POST-PROCESSING---------------------------------------------------------------------------------------\n",
    "normalized_img_bw = cv2.cvtColor(normalized_img, cv2.COLOR_BGR2GRAY)                                       #convert rescaled center image to black and white channels for post-processing\n",
    "thr_value2, th_shape_img = cv2.threshold(normalized_img_bw, 0, 250,cv2.THRESH_OTSU)              #accurate countours, smoother edges compared to regular binary\n",
    "kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "morph_shape_img = cv2.morphologyEx(th_shape_img , cv2.MORPH_CLOSE, kernel_close)                        #erosion + dilute method (internal spaces removal)\n",
    "canny_shape_img = cv2.Canny(morph_shape_img, 150, 500)  \n",
    "\n",
    "\n",
    "\n",
    "contours_shape, hierarchy_shape = cv2.findContours(canny_shape_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "print(type(contours_shape), len(contours_shape))\n",
    "for i, c in enumerate(contours_shape):         # loop through all the found contours\n",
    "    perimeter = cv2.arcLength(c, True)     # perimeter of contour c (curved length)     \n",
    "    area = cv2.contourArea(c) \n",
    "    polygon_constant = 0.04    # try changing this value to get more or less corners\n",
    "    corners = len(cv2.approxPolyDP(c, polygon_constant*perimeter, True)) \n",
    "    ellipse = cv2.fitEllipse(c)    # fit an ellipse on the contour\n",
    "    (center, axes, orientation) = ellipse   # extract the main parameter\n",
    "    majoraxis_length = max(axes)\n",
    "    minoraxis_length = min(axes)\n",
    "    #print(area)\n",
    "    if not 4 < corners < 15 or 15 < area/perimeter < 25 or 1.4 < (majoraxis_length/minoraxis_length) < 1.6:\n",
    "        contours_shape.pop(i) \n",
    "    print(type(contours_shape), len(contours_shape))\n",
    "\n",
    "\n",
    "\n",
    "shape_selectedcountour = 7\n",
    "drawn_shape_contours_img = cv2.drawContours(normalized_img, contours_shape, shape_selectedcountour, (0,255,0), 2, cv2.LINE_AA)\n",
    "cv2.imshow('drawn_shape_contours_img', drawn_shape_contours_img)\n",
    "cv2.imshow('morph_shape_img', morph_shape_img) \n",
    "\n",
    "mask = np.zeros_like(morph_shape_img) # Create mask where white is what we want, black otherwise\n",
    "cv2.drawContours(mask, contours_shape, shape_selectedcountour, 255, -1) # Draw filled contour in mask\n",
    "center_masked = np.zeros_like(morph_shape_img) # Extract out the object and place into output image\n",
    "center_masked[mask == 255] = morph_shape_img[mask == 255]\n",
    "cv2.imshow('center_masked', center_masked)\n",
    "\n",
    "#---------------------------------------------------------------------------------------FEATURE SPACE RECOGNITION---------------------------------------------------------------------------------------\n",
    "perimeter = cv2.arcLength(contours_shape[shape_selectedcountour], True)\n",
    "area = cv2.contourArea(contours_shape[shape_selectedcountour])\n",
    "polygon_constant = 0.04    # try changing this value to get more or less corners\n",
    "corners = len(cv2.approxPolyDP(contours_shape[shape_selectedcountour], polygon_constant*perimeter, True)) \n",
    "print(area/perimeter, corners)\n",
    "\n",
    "\n",
    "ellipse = cv2.fitEllipse(contours_shape[shape_selectedcountour])    # fit an ellipse on the contour\n",
    "(center, axes, orientation) = ellipse   # extract the main parameter\n",
    "majoraxis_length = max(axes)\n",
    "minoraxis_length = min(axes)\n",
    "\n",
    "print(\"Tallness: \", majoraxis_length/minoraxis_length)\n",
    "\n",
    "\n",
    "\n",
    "harris_method_RGB_img= cv2.cvtColor(center_masked.copy(),cv2.COLOR_GRAY2RGB)\n",
    "harris_method_bw_img = np.float32(cv2.cvtColor(harris_method_RGB_img, cv2.COLOR_BGR2GRAY))\n",
    "dst = cv2.cornerHarris(harris_method_bw_img,2,3,0.04)\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "harris_method_RGB_img[dst>0.01*dst.max()]=[0,0,255]\n",
    "cv2.imshow('harris',harris_method_RGB_img)\n",
    "\n",
    "thresh = math.exp(19)\n",
    "harris_corners = 0\n",
    "for i in range(dst.shape[0]):\n",
    "    for j in range(dst.shape[1]):\n",
    "        if int(dst[i,j]) > thresh:\n",
    "            harris_corners = harris_corners + 1\n",
    "print(\"Harris corners: \", harris_corners)\n",
    "\n",
    "\n",
    "shi_tomasi_RGB_img= cv2.cvtColor(center_masked.copy(),cv2.COLOR_GRAY2RGB)\n",
    "shi_tomasi_method_bw_img = cv2.cvtColor(shi_tomasi_RGB_img, cv2.COLOR_BGR2GRAY)\n",
    "corners = cv2.goodFeaturesToTrack(shi_tomasi_method_bw_img, 0, 0.25, 0.05)\n",
    "  \n",
    "corners = np.int0(corners)\n",
    "print(\"Shi-Tomasi Corners Detected: \", corners)\n",
    "# draw red color circles on all corners\n",
    "for i in corners:\n",
    "    x, y = i.ravel()\n",
    "    cv2.circle(shi_tomasi_RGB_img, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow('shi_tomasi',shi_tomasi_RGB_img)\n",
    "\n",
    "\n",
    "\n",
    "houghcircles_RGB_img= contour_cropped_analysis_img.copy()\n",
    "houghcircles_bw_img = cv2.cvtColor(houghcircles_RGB_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "rows = houghcircles_bw_img.shape[0]\n",
    "circles = cv2.HoughCircles(houghcircles_bw_img, cv2.HOUGH_GRADIENT, 1, rows / 16,\n",
    "                           param1=100, param2=30,\n",
    "                           minRadius=34, maxRadius=35)\n",
    "print(type(circles), circles)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :]:\n",
    "        center = (i[0], i[1])\n",
    "        # circle center\n",
    "        cv2.circle(houghcircles_RGB_img, center, 1, (0, 100, 100), 3)\n",
    "        # circle outline\n",
    "        radius = i[2]\n",
    "        cv2.circle(houghcircles_RGB_img, center, radius, (255, 0, 255), 3)\n",
    "\n",
    "cv2.imshow('houghcircles_RGB_img',houghcircles_RGB_img)\n",
    "\n",
    "#------------------------------------------------------------------------------------IDENTIFICATION TEXT PLACEMENT--------------------------------------------------------------------------------------                                                                      \n",
    "disp_x = +240                                                                                          #perfect value = +240\n",
    "disp_y = -165                                                                                          #perfect value = -165\n",
    "text_displayed = (named_colour + \" \" + \" uno card\").upper()\n",
    "identified_img = cv2.putText(colour_framed_img,                                                        #create text on top of image\n",
    "                             text_displayed,                                                           #set text to text_displayed string\n",
    "                             (y_cnt+disp_y, x_cnt+disp_x),                                             #set coords to contour bottom right corner with displacement\n",
    "                             cv2.FONT_HERSHEY_SIMPLEX,                                                 #set OpenCV font\n",
    "                             0.4, (0,255,0), 1, cv2.LINE_AA)                                           #font size, colour, thickness, antialiasing on the text for smoother edges\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------POST-PROCESSED IMAGE SCALLING-------------------------------------------------------------------------------------                                                                                             \n",
    "scaling = int(identified_img.shape[1]*1.5),int(identified_img.shape[0]*1.5)                            #scale the output image by 1.5x\n",
    "final_img = cv2.resize(identified_img, scaling, interpolation = cv2.INTER_AREA)                        #scale the identified_img, with scaling resolution\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------IMAGE DISPLAY---------------------------------------------------------------------------------------------- \n",
    "cv2.imshow('original', colour_img)                                                                     #show the original image to the user\n",
    "#cv2.imshow('cropped', contour_cropped_analysis_img)                                                    #show the contour cropped image to the user\n",
    "cv2.imshow('final_img', final_img)                                                                     #show the final image to the user\n",
    "  \n",
    "cv2.imshow('canny_shape_img', canny_shape_img)   \n",
    "\n",
    "\n",
    "\n",
    "key = cv2.waitKey(0)                                                                                   #wait for any key press\n",
    "cv2.destroyAllWindows()                                                                                #close all windows displaying images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
