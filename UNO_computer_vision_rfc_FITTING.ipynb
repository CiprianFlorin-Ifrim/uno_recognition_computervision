{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b48c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 100 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=8.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}\n",
      "Fitting 8 folds for each of 1575 candidates, totalling 12600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=8.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "G:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.78571429 0.77380952 0.78571429]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 85, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "The entire optimisation process took:  04m:30s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resources:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "https://stats.stackexchange.com/questions/27730/choice-of-k-in-k-fold-cross-validation\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\"\"\"\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                  #change width of Jupyer Notebook to use the whole window resolution available\n",
    "\n",
    "def code_timer(tstart,tstop):\n",
    "    process_time = (tstop-tstart)\n",
    "    mins, sec = divmod(process_time, 60)                                                        # split to hours and seconds\n",
    "    return '{:02.0f}m:{:02.0f}s'.format(mins,sec) \n",
    "\n",
    "\n",
    "dataset = pd.read_csv('./dataset.csv',header=None)\n",
    "#display(dataset)\n",
    "X_train = dataset.iloc[:, 1:] \n",
    "y_train = dataset.iloc[:, 0]\n",
    "#display(X)\n",
    "#display(y)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "X_reduced = PCA(n_components=3).fit_transform(X_train)\n",
    "pca = PCA(4)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\"\"\"\n",
    "\n",
    "timer_start = time.monotonic()\n",
    "rfc = RandomForestClassifier()\n",
    "param_random = { \n",
    "    'n_estimators': [100, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "    'bootstrap': [True, False]}\n",
    "\n",
    "rfc_random_search = RandomizedSearchCV(estimator = rfc, param_distributions = param_random, \n",
    "                                       n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rfc_random_search.fit(X_train, y_train)\n",
    "best_random_search = list(rfc_random_search.best_params_.values())\n",
    "print(rfc_random_search.best_params_)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [int(best_random_search[0]-100), int(best_random_search[0]-50), int(best_random_search[0]-25), int(best_random_search[0]),\n",
    "                                                int(best_random_search[0]+25), int(best_random_search[0])+50, int(best_random_search[0])+100],\n",
    "    'min_samples_split': [int(best_random_search[1]/3), int(best_random_search[1]/2), int(best_random_search[1]), \n",
    "                                                     int(best_random_search[1]*2), int(best_random_search[1]*3)],\n",
    "    'min_samples_leaf': [best_random_search[2]-1, best_random_search[1], best_random_search[1]+1],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [best_random_search[4]-10, best_random_search[4]-5, best_random_search[4], \n",
    "                                        best_random_search[4]+5, best_random_search[4]+10],\n",
    "    'bootstrap': [best_random_search[5]]}\n",
    "\n",
    "rfc_grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                               cv = 5, n_jobs = -1, verbose = 2)\n",
    "rfc_grid_search.fit(X_train, y_train)\n",
    "best_grid_search = list(rfc_grid_search.best_params_.values())\n",
    "print(rfc_grid_search.best_params_)\n",
    "\n",
    "rfc_optimised = RandomForestClassifier(n_jobs=-1, bootstrap=best_grid_search[0], max_depth=best_grid_search[1], max_features=best_grid_search[2],\n",
    "                                       min_samples_leaf=best_grid_search[3], min_samples_split=best_grid_search[4], n_estimators=best_grid_search[5])\n",
    "rfc_optimised.fit(X_train,y_train)\n",
    "pickle.dump(rfc_optimised, open(\"randomforest_clf_optimised.p\", \"wb\"))\n",
    "\n",
    "timer_stop = time.monotonic()\n",
    "print(\"The entire optimisation process took: \", code_timer(timer_start, timer_stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa6fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
