{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750f684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------LIBRARIES------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import time                                                                                                          #provides various time-related functions\n",
    "import math                                                                                                          #provides access to the mathematical functions defined by the C standard\n",
    "import operator                                                                                                      #additional efficient python fucntions \n",
    "import csv                                                                                                           #implements classes to read and write tabular data in CSV format                                                                                                  \n",
    "import glob                                                                                                          #finds all the pathnames matching a specified pattern according to unix shell\n",
    "import cv2                                                                                                           #import OpenCV2 library for image processing\n",
    "import pickle                                                                                                        #implements binary protocols for serializing and de-serializing an object structure\n",
    "import numpy as np                                                                                                   #import numpy mathematical library\n",
    "import pandas as pd                                                                                                  #offers data structures and operations for manipulating numerical tables \n",
    "import matplotlib.pyplot as plt                                                                                      #import matplotlib library for plotting\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter.filedialog import askdirectory\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "from scipy import ndimage                                                                                            #package contains various functions for multidimensional image processing      \n",
    "from sklearn.decomposition import PCA                                                                                #Linear dimensionality reduction using Singular Value Decomposition\n",
    "from sklearn.ensemble import RandomForestClassifier                                                                  #meta estimator that fits a number of decision tree classifiers on various sub-samples\n",
    "from sklearn.model_selection import train_test_split                                                                 #quick utility for spliting data(ML) in a oneliner\n",
    "from sklearn.model_selection import RandomizedSearchCV                                                               #method for cross-validated search over parameter settings for hyperparameters optimisation\n",
    "from sklearn.model_selection import GridSearchCV                                                                     #exhaustive search over specified parameter values for an estimator\n",
    "from webcolors import rgb_to_name, name_to_rgb                                                                       #import the webcolors library which enables RGB to name and vice versa conversions\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                                #change width of Jupyer Notebook to use the whole window resolution available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba12ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------VARIABLES------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#development note: the hsv ranges are here to be used both for the cards as well as the camera stream by recalling them rather than reassigning\n",
    "red_lower1 = np.array([0, 50, 20], np.uint8)\n",
    "red_upper1 = np.array([10, 255, 255], np.uint8) \n",
    "red_lower2 = np.array([160, 90, 90], np.uint8)\n",
    "red_upper2 = np.array([180, 255, 255], np.uint8)\n",
    "\n",
    "green_lower = np.array([45, 100, 50], np.uint8)                                     #set the lower HSV range for the GREEN colour                                                  \n",
    "green_upper = np.array([75, 255, 255], np.uint8)                                                     \n",
    " \n",
    "blue_lower = np.array([87, 150, 80], np.uint8)                                      #set the lower HSV range for the BLUE colour\n",
    "blue_upper = np.array([117, 255, 255], np.uint8)                                                    \n",
    "\n",
    "yellow_lower = np.array([15, 90, 80], np.uint8) \n",
    "yellow_upper = np.array([40, 255, 255], np.uint8)\n",
    "\n",
    "black_lower = np.array([0, 0, 0], np.uint8)                                          #set the lower HSV range for the BLACK colour\n",
    "black_upper = np.array([20, 20, 40], np.uint8)                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5262dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------DEFINITIONS-------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def code_timer(tstart,tstop):\n",
    "    process_time = (tstop-tstart)\n",
    "    mins, sec = divmod(process_time, 60)                                                        # split to minutes and seconds\n",
    "    return '{:02.0f} min:{:02.0f} sec'.format(mins,sec) \n",
    "\n",
    "def map_value(value, in_low, in_high, out_low, out_high):                                              #create Arduino map() function in python for usage throughout the code\n",
    "    return out_low + (out_high - out_low) * ((value - in_low) / (in_high - in_low))                    #scale input lowest,input highest range to output lowest,output highest range then return\n",
    "\n",
    "def calculateDistance(x1,y1,x2,y2):\n",
    "    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return dist\n",
    "\n",
    "def to_bw(image):\n",
    "    output = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return output\n",
    "\n",
    "def rotate_img(img, angle):\n",
    "    result = ndimage.rotate(img, angle) \n",
    "    return result \n",
    "\n",
    "def find_contours(img_cnt, method, sigma = 0.33):\n",
    "    img_cnt_bw = to_bw(img_cnt)                                                             #convert rescaled center image to black and white channels for post-processing\n",
    "    blurred = cv2.GaussianBlur(img_cnt_bw, (3, 3), 0)\n",
    "    th_cnt_value, th_cnt_img = cv2.threshold(blurred,100,200,cv2.THRESH_OTSU)                    #accurate countours, smoother edges compared to regular binary\n",
    "    kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "    morph_cnt_img = cv2.morphologyEx(th_cnt_img, cv2.MORPH_CLOSE, kernel_close)                       #erosion + dilute method (internal spaces removal)\n",
    "    \n",
    "    v = np.median(morph_cnt_img)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(morph_cnt_img, lower, upper) \n",
    "    \n",
    "    if method == \"EXTERNAL\":\n",
    "        contours_img_cnt, hierarchy_img_cnt = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    elif method == \"TREE\":\n",
    "        contours_img_cnt, hierarchy_img_cnt = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    return contours_img_cnt, hierarchy_img_cnt, edged\n",
    "\n",
    "def contour_removal_properties(image, min_corners, max_corners, min_ratio, max_ratio, min_height, max_height):\n",
    "    contours_found, __ = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    for c, cnt in enumerate(contours_found):                                                           # loop through all the found contours\n",
    "        perimeter, area, corners = contour_properties(cnt)\n",
    "        height, width = shape_height_width(cnt)\n",
    "        if not min_corners < corners < max_corners or min_ratio < area/perimeter < max_ratio or min_height < height < max_height:\n",
    "            contours_found.pop(c) \n",
    "    return contours_found\n",
    "\n",
    "def contour_removal_distance_centerpoints(contour_space, contour_space_center_x, contour_space_center_y, dist_min):\n",
    "    for i, cnt in enumerate(contour_space):\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        if ((((cx - contour_space_center_x)**2) + ((contour_space_center_y)**2))**0.5) > dist_min:\n",
    "            contours_space.pop(i)\n",
    "    return contour_space\n",
    "\n",
    "def draw_selected_contour(original, contour_space, contour, R,G,B, thickness):\n",
    "    drawn_contours_img = cv2.drawContours(original, contour_space[contour], -1, (R,G,B), thickness, cv2.LINE_AA)\n",
    "    return drawn_contours_img\n",
    "\n",
    "def yougest_children_img(image_children):\n",
    "    contours_space_cnt, hierarchy_space_cnt, ____= find_contours(image_children, \"TREE\")\n",
    "    hierarchy_space_cnt = hierarchy_space_cnt[0]\n",
    "    hierarchy_children_img = image_children.copy()\n",
    "    children_found = 0\n",
    "    for component in zip(contours_space_cnt, hierarchy_space_cnt):\n",
    "        currentContour = component[0]\n",
    "        currentHierarchy = component[1]\n",
    "        x,y,w,h = cv2.boundingRect(currentContour)\n",
    "        if currentHierarchy[2] < 0:                                                                            # these are the innermost child components            \n",
    "            cv2.rectangle(hierarchy_children_img ,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "            children_found += 1\n",
    "    return children_found, hierarchy_children_img\n",
    "\n",
    "def find_center(image):\n",
    "    contour_bw = to_bw(image)                                                              #convert rescaled center image to black and white channels for post-processing\n",
    "    thr_value2, th_shape_img = cv2.threshold(contour_bw,127,255,cv2.THRESH_OTSU)                    #accurate countours, smoother edges compared to regular binary\n",
    "    kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "    morph_shape_img = cv2.morphologyEx(th_shape_img , cv2.MORPH_CLOSE, kernel_close)                       #erosion + dilute method (internal spaces removal)\n",
    "    canny_shape_img = cv2.Canny(morph_shape_img, 150, 500)  \n",
    "    contours_shape, hierarchy_shape = cv2.findContours(canny_shape_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "    center_identified_img = image.copy()\n",
    "    M = cv2.moments(contours_shape[1])\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.circle(center_identified_img, (cx, cy), 7, (0, 0, 255), -1)\n",
    "        cv2.putText(center_identified_img, \"CENTER\", (cx - 30, cy - 10),\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        return center_identified_img, cx, cy\n",
    "    else:\n",
    "        return center_identified_img, 0, 0\n",
    "\n",
    "def contour_extraction(image, contours_space, cnt):\n",
    "    mask = np.zeros_like(image) # Create mask where white is what we want, black otherwise\n",
    "    cv2.drawContours(mask, contours_space, cnt, 255, -1) # Draw filled contour in mask\n",
    "    masked = np.zeros_like(image) # Extract out the object and place into output image\n",
    "    masked[mask == 255] = image[mask == 255]\n",
    "    return masked\n",
    "\n",
    "def contour_bound_crop(img, cnts, cnt):\n",
    "    [x,y,w,h] = cv2.boundingRect(cnts[cnt])\n",
    "    box = cv2.rectangle(img.copy(), (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "    cropped = img[y-10:y+h+10, x-10:x+w+10]\n",
    "    return cropped, box\n",
    "\n",
    "def sharpen_image(image, sharpness, threshold):\n",
    "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, (5,5) , 1.0)\n",
    "    sharpened = float(sharpness + 1) * image - float(sharpness) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "def contour_properties(contour_selected, req):\n",
    "    perimeter = cv2.arcLength(contour_selected, True)                                                                    # perimeter of contour c (curved length)     \n",
    "    area = cv2.contourArea(contour_selected)                                                                     \n",
    "    corners = len(cv2.approxPolyDP(contour_selected, 0.04*perimeter, True))\n",
    "    if req == \"A\":\n",
    "        return area\n",
    "    elif req == \"P\":\n",
    "        return perimeter\n",
    "    elif req == \"C\":\n",
    "        return corners\n",
    "\n",
    "def shape_ratio(perimeter, area):\n",
    "    ratio = area/perimeter   \n",
    "    return ratio\n",
    "\n",
    "def fit_ellipse(contour_selected):\n",
    "    try:\n",
    "        ellipse_found = cv2.fitEllipse(contour_selected)                                                                      # fit an ellipse on the contour\n",
    "        (center, axes, orientation) = ellipse_found                                                            # extract the main parameter\n",
    "        majoraxis_length = max(axes)                              \n",
    "        minoraxis_length = min(axes)\n",
    "        return minoraxis_length, majoraxis_length\n",
    "    except (cv2.error, ZeroDivisionError) as e:\n",
    "        return 0, 0\n",
    "\n",
    "def shape_height_width(contour_selected, val):\n",
    "    try:\n",
    "        minor, major = fit_ellipse(contour_selected)\n",
    "        if val == \"H\":\n",
    "            return major/minor\n",
    "        if val == \"W\":\n",
    "            return minor/major\n",
    "    except (cv2.error, ZeroDivisionError) as e:\n",
    "        return 0\n",
    "\n",
    "def contour_masking(morphology, cnts, selected):\n",
    "    mask = np.zeros_like(morphology)                                                               # Create mask where white is what we want, black otherwise\n",
    "    cv2.drawContours(mask, cnts, selected, 255, -1)                                       # Draw filled contour in mask\n",
    "    masked = np.zeros_like(morphology)                                                              #Extract out the object and place into output image\n",
    "    masked[mask == 255] = morphology[mask == 255]\n",
    "    return masked\n",
    "\n",
    "def harris_method_corners(image):\n",
    "    harris_method_BGR_img= image.copy()\n",
    "    harris_method_bw_img = np.float32(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "    dst = cv2.cornerHarris(harris_method_bw_img,5,3,0.04)\n",
    "    ret, dst = cv2.threshold(dst,0.1*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    harris_corners = cv2.cornerSubPix(harris_method_bw_img,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "    harris_method_BGR_img[dst>0.1*dst.max()]=[0,0,255]   \n",
    "    \n",
    "    for c in range(1, len(harris_corners)):\n",
    "        cv2.circle(harris_method_BGR_img, (int(harris_corners[c,0]), int(harris_corners[c,1])), 7, (0,255,0), 2)\n",
    "    \n",
    "    return c, harris_method_BGR_img\n",
    "\n",
    "def shi_tomasi_method_corners(image):\n",
    "    shi_tomasi_BGR_img= image.copy()\n",
    "    shi_tomasi_method_bw_img = cv2.cvtColor(shi_tomasi_BGR_img, cv2.COLOR_BGR2GRAY)\n",
    "    shi_tomasi_corners = cv2.goodFeaturesToTrack(shi_tomasi_method_bw_img, 0, 0.25, 0.05)\n",
    "    shi_tomasi_corners = np.int0(shi_tomasi_corners)\n",
    "                                                                                                  \n",
    "    for i in shi_tomasi_corners:                                                                                    # draw red color circles on all corners\n",
    "        x, y = i.ravel()\n",
    "        cv2.circle(shi_tomasi_BGR_img, (x, y), 3, (0, 0, 255), -1)\n",
    "    return len(shi_tomasi_corners), shi_tomasi_BGR_img\n",
    "\n",
    "def houghcircles(image, min_radius, max_radius, circle_dist):\n",
    "    ___, center_x, center_y = find_center(image)\n",
    "    circles_count = 0   \n",
    "    houghcircles_BGR_img= image.copy()\n",
    "    houghcircles_bw_img = cv2.cvtColor(houghcircles_BGR_img, cv2.COLOR_BGR2GRAY)\n",
    "    rows = houghcircles_bw_img.shape[0]\n",
    "    circles = cv2.HoughCircles(houghcircles_bw_img, cv2.HOUGH_GRADIENT, 1, rows / circle_dist,\n",
    "                               param1=100, param2=30, minRadius=min_radius, maxRadius=max_radius)\n",
    "    \n",
    "    dist_center_circle = 0\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1]) \n",
    "            dist_center_circle += int(calculateDistance(center[0],center[1],center_x,center_y))\n",
    "            cv2.circle(houghcircles_BGR_img, center, 1, (0, 100, 100), 3)                           # circle center           \n",
    "            radius = i[2]                                                                              # circle outline\n",
    "            cv2.circle(houghcircles_BGR_img, center, radius, (255, 0, 255), 3)\n",
    "        circles_count = int(circles.size/3)\n",
    "    return circles_count, houghcircles_BGR_img, dist_center_circle\n",
    "\n",
    "def houghlines(image, canny_edges):\n",
    "    lines_img = image.copy()\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 10  # angular resolution in radians of the Hough grid\n",
    "    threshold = 17 # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15  # minimum number of pixels making up a line\n",
    "    max_line_gap = 18 # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(image) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(canny_edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    line_counter = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                line_counter += 1\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),5)\n",
    "\n",
    "        lines_edges = cv2.addWeighted(lines_img, 1, line_image, 1, 0)\n",
    "\n",
    "        parallel = []\n",
    "        for i in range(len(lines)):\n",
    "            for j in range(len(lines)):\n",
    "                if (i == j):continue\n",
    "                if (abs(lines[i][0][1] - lines[j][0][1]) == 0):         \n",
    "                    parallel.append((i,j))\n",
    "        return line_counter, lines_edges, len(parallel)\n",
    "    \n",
    "def center_shape(img_frame, mina, maxa, b, g, r):\n",
    "    mask = np.zeros_like(img_frame)\n",
    "    rows, cols,_ = mask.shape\n",
    "    center_x = int(rows/2)\n",
    "    center_y = int(cols/2)\n",
    "    center = (center_y,center_x)\n",
    "\n",
    "    mask = cv2.ellipse(mask, center, axes=(mina, maxa), angle=24, startAngle=0, endAngle = 360, color=(255,255,255), thickness = -1)\n",
    "    ellipse_masked_img = np.bitwise_and(img_frame, mask)\n",
    "    ellipse_masked_img[np.all(ellipse_masked_img == (0, 0, 0), axis=-1)] = (b, g, r)\n",
    "\n",
    "    return ellipse_masked_img\n",
    "\n",
    "def card_type_name(filepath):\n",
    "    card_type = filepath[-5:-4]\n",
    "    if card_type == \"R\":\n",
    "        card_type = 10;\n",
    "    elif card_type == \"S\":\n",
    "        card_type = 11;\n",
    "    elif card_type == \"T\":\n",
    "        card_type = 12;\n",
    "    elif card_type == \"B\":\n",
    "        card_type = 13;    \n",
    "    elif card_type == \"E\":\n",
    "        card_type = 14;  \n",
    "    elif card_type == \"F\":\n",
    "        card_type = 15;  \n",
    "    elif card_type == \"W\":\n",
    "        card_type = 16;  \n",
    "    else:\n",
    "        card_type = int(filepath[-5:-4])\n",
    "    return card_type\n",
    "\n",
    "def result_processing(variable):\n",
    "    if variable == 10:\n",
    "        variable = \"REVERSE\";\n",
    "    elif variable == 11:\n",
    "        variable = \"SKIP\";\n",
    "    elif variable == 12:\n",
    "        variable = \"PLUS 2\";\n",
    "    elif variable == 13:\n",
    "        variable = \"EMPTY\";    \n",
    "    elif variable == 14:\n",
    "        variable = \"SHUFFLE\";  \n",
    "    elif variable == 15:\n",
    "        variable = \"PLUS 4\";  \n",
    "    elif variable == 15:\n",
    "        variable = \"WILD\";  \n",
    "    else:\n",
    "        variable = variable\n",
    "    return variable   \n",
    "\n",
    "def features_extraction(contours_center, hierarchy_center, center_processing, canny_center_processing):\n",
    "    contours_final = list()\n",
    "    hierarchy_center = hierarchy_center[0]\n",
    "    for component in zip(contours_center, hierarchy_center):\n",
    "        currentContour = component[0]\n",
    "        currentHierarchy = component[1]\n",
    "        if currentHierarchy[2] < 0:\n",
    "            contours_final.append(currentContour)\n",
    "\n",
    "    height_found, width_found, area_found, perimeter_found, poly_corners_found = 0,0,0,0,0\n",
    "    for c in range(len(contours_final)):\n",
    "        drawn_contour_img = draw_selected_contour(center_processing.copy(), contours_final, c, 0,255,0, 2)\n",
    "        area_found += contour_properties(contours_final[c], \"A\")\n",
    "        perimeter_found += contour_properties(contours_final[c], \"P\")\n",
    "        poly_corners_found += contour_properties(contours_final[c], \"C\")\n",
    "        height_found += shape_height_width(contours_final[c], \"H\") \n",
    "        width_found += shape_height_width(contours_final[c], \"W\") \n",
    "\n",
    "    ratio_found = shape_ratio(perimeter_found, area_found)    \n",
    "    harris_corners, harris_corners_img = harris_method_corners(center_processing)\n",
    "    shi_tomasi_corners, shi_tomasi_img = shi_tomasi_method_corners(center_processing)\n",
    "    lines_found, lines_found_image, parallel_instances_found = houghlines(center_processing, canny_center_processing)\n",
    "    circles_found, houghcircles_img, dist_from_center = houghcircles(center_processing, 20, 30, 8)\n",
    "    children_found_counter, children_found_img = yougest_children_img(center_processing)\n",
    "\n",
    "    features = [int(-(-ratio_found // 1)), float(\"{:.1f}\".format(height_found)), float(\"{:.1f}\".format(width_found)), children_found_counter, \n",
    "                                lines_found, parallel_instances_found, circles_found, dist_from_center, harris_corners, shi_tomasi_corners, poly_corners_found]\n",
    "    \n",
    "    titles = ['Ellipse Masked','Drawn Shape','Shi-Tomasi Corners','Harris Corners','Hough Circles','Children Found','Lines Found']\n",
    "    images = [center_processing, drawn_contour_img, shi_tomasi_img, harris_corners_img, houghcircles_img, children_found_img, lines_found_image]\n",
    "    \n",
    "    return features, titles, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf555c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------MAIN CODE---------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def main_code(image_filename, menu_colour):\n",
    "    input_img = cv2.imread(image_filename)                                                                 #load the image from the specified path\n",
    "    rotated_img = rotate_img(input_img, -90)                                                               #rotate image by 90 degrees, increase user ease of use\n",
    "    bw_img = to_bw(rotated_img)                                                                            #convert to a black and white image\n",
    "\n",
    "#-------------------------------------------------------------------------------------------POST-PROCESSING-----------------------------------------------------------------------------------------\n",
    "    thr_value, th_img = cv2.threshold(bw_img,150, 400, cv2.THRESH_BINARY_INV)                              #accurate countours, smoother edges compared to regular binary\n",
    "    kernel = np.ones((3, 3), np.uint8)                                                                     #higher kernel = less accurate contours\n",
    "    #close_img = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)                                         #erosion + dilute method (internal spaces removal)\n",
    "    open_img = cv2.morphologyEx(th_img, cv2.MORPH_OPEN, kernel)                                            #dilute + erosion method (noise removal)\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------------EDGE DETENCTION & CONTOUR MAPPING---------------------------------------------------------------------------------\n",
    "    canny_img = cv2.Canny(open_img, 50, 100)                                                               #edge detection using the OpenCV Canny method\n",
    "    #cv2.imshow('test',canny_img)\n",
    "    contours, _ = cv2.findContours(open_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  \n",
    "    selected_contour = 1                                                                                   #0 = frame; 1 = uno card perimeter; \n",
    "    contours_img = draw_selected_contour(rotated_img, contours, selected_contour, 0,255,0, 2)              #draw selected contour on top of the rotated colour image\n",
    "    #print(len(contours))                                                                                  #debugging: show how many contours have been found\n",
    "    #print(hierarchy)                                                                                      #debugging: show hierarchy list for all contours\n",
    "\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------OPEN CV CONTOUR CROPPING USING CONTOURS FUNCTION--------------------------------------------------------------------------- \n",
    "    x_cnt,y_cnt,w_cnt,h_cnt = cv2.boundingRect(contours[selected_contour])                                 #find origin, width and heigth of image based on selected_contour\n",
    "    contour_cropped_proc_img = (rotated_img.copy())[y_cnt-7:y_cnt+h_cnt+7, x_cnt-7:x_cnt+w_cnt+7]          #crop the image based on the coordinates found for processing\n",
    "    #print(x_cnt, y_cnt, w_cnt, h_cnt)                                                                     #print 4 values for debugging\n",
    "\n",
    "    #---------------------------------------------------------------------------RESOLUTION NORMALIZATION--------------------------------------------------------------------------- \n",
    "    resolution_input_img = list(contour_cropped_proc_img.shape)\n",
    "    resolution_input_img = resolution_input_img[:-1]\n",
    "    #print(resolution_input_img, type(resolution_input_img))\n",
    "\n",
    "    if resolution_input_img[1] > resolution_input_img[0]:\n",
    "        contour_cropped_proc_img = cv2.resize(contour_cropped_proc_img, (260, 173)) \n",
    "    else:\n",
    "        contour_cropped_proc_img = cv2.resize(contour_cropped_proc_img, (173, 260))\n",
    "\n",
    "    contour_cropped_analysis_img = contour_cropped_proc_img.copy()                                #crop the rotated original image copy with the uno card contour for pattern/colour processing\n",
    "    #---------------------------------------------------------------------------DISPLAY FRAME--------------------------------------------------------------------------- \n",
    "    framed_img = cv2.copyMakeBorder(contour_cropped_proc_img,                                              #add a 30px wide black frame around the cropped image (helps with text placement) \n",
    "                                    30,30,30,30,\n",
    "                                    cv2.BORDER_CONSTANT,\n",
    "                                    value=(0,0,0)) \n",
    "\n",
    "    #-----------------------------------------------------------------------------------------COLOUR ANALYSIS------------------------------------------------------------------------------------------ \n",
    "    #a patch of pixels is chosen to increase accuracy \n",
    "    #as well as optimise the code by running through less pixels in the functions to follow\n",
    "    center_analysis_img, center_analysis_x, center_analysis_y = find_center(contour_cropped_analysis_img)\n",
    "    colour_patch_img = contour_cropped_analysis_img[center_analysis_y-55:center_analysis_y-45,center_analysis_x-225:center_analysis_x-215]                                        #select a constant patch from the uno card image to perform the pixel analysis\n",
    "\n",
    "    bgr_pixels = colour_patch_img.tolist()                                                                 #transform patch array to list containing bgr tuples\n",
    "    #print(bgr_pixels)\n",
    "    b = [x[0][0] for x in bgr_pixels]                                                                      #extract blue values from bgr list\n",
    "    g = [x[0][1] for x in bgr_pixels]                                                                      #extract green values from bgr list\n",
    "    r = [x[0][2] for x in bgr_pixels]                                                                      #extract red values from bgr list\n",
    "    frequent_b = (max(set(b), key = b.count))                                                              #find the most frequent blue value in the image patch selected\n",
    "    frequent_g = (max(set(g), key = g.count))                                                              #find the most frequent green value in the image patch selected\n",
    "    frequent_r = (max(set(r), key = r.count))                                                              #find the most frequent red value in the image patch selected\n",
    "\n",
    "    if (menu_colour == 1):                                                                        #If input is 1:\n",
    "        #-----------------------------------------------------------------------------------------COLOUR IDENTIFICATION - METHOD 1------------------------------------------------------------------------------------------  \n",
    "        rgb_dictionary = {\"red\": frequent_r, \"green\": frequent_g, \"blue\": frequent_b}                          #create dictionary containing the RGB colour space, and assign most frequent value from patch\n",
    "        sorted_rgb_dictionary = dict((y, x) for y, x in sorted(rgb_dictionary.items(),                         #sort dictionary based on value, not key and since the output is a tuple, transform to dictionary\n",
    "                                                               key=operator.itemgetter(1)))                    #choose value for sorting process, (1) = value, (0) = key\n",
    "        highest_rgb_value = list(sorted_rgb_dictionary)[2]                                                     #extract highest value whether it is a blue, green or red pixel (key)\n",
    "        middle_rgb_value = list(sorted_rgb_dictionary)[1]                                                      #extract middle value whether it is a blue, green or red pixel (key)\n",
    "        lowest_rgb_value = list(sorted_rgb_dictionary)[0]                                                      #extract lowest value whether it is a blue, green or red pixel (key)\n",
    "\n",
    "        #the following part of the code changes the R,G,B values of the pixels to an extreme\n",
    "        #this helps identify the colour correctly with different levels of brightness in the image\n",
    "        colour_rgb = [0,0,0]                                                                                   #create list to store the new RGB values for colour identification\n",
    "        if sorted_rgb_dictionary.get(highest_rgb_value) >= 255/2:                                              #if the highest pixel value is higher than the mid-point, then:\n",
    "            if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "                colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "            elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "                colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "            elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "                colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "        if sorted_rgb_dictionary.get(highest_rgb_value) <= 255/2:                                            #if the highest pixel value is lower than the mid-point, then:\n",
    "            if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "                colour_rgb[0] = 128                                                                                #assign the first element in the colour_rgb = 128 \n",
    "            elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "                colour_rgb[1] = 128                                                                                #assign the second element in the colour_rgb = 128 \n",
    "            elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "                colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 128 \n",
    "        if sorted_rgb_dictionary.get(middle_rgb_value) > 130:                                               #if the middle pixel value is higher than 150, then:\n",
    "            if middle_rgb_value == \"red\":                                                                      #if the middle_rgb_value is a \"red\" pixel, then:\n",
    "                colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "            elif middle_rgb_value == \"green\":                                                                  #if the middle_rgb_value is a \"green\" pixel, then:\n",
    "                colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "            elif middle_rgb_value == \"blue\":                                                                   #if the middle_rgb_value is a \"blue\" pixel, then:\n",
    "                colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "        if sorted_rgb_dictionary.get(middle_rgb_value) <= 130:                                                  #if the middle pixel value is higher than 150, then:\n",
    "            if middle_rgb_value == \"red\":                                                                      #if the middle_rgb_value is a \"red\" pixel, then:\n",
    "                colour_rgb[0] = 0                                                                               #assign the first element in the colour_rgb = 255 \n",
    "            elif middle_rgb_value == \"green\":                                                                  #if the middle_rgb_value is a \"green\" pixel, then:\n",
    "                colour_rgb[1] = 0                                                                                  #assign the second element in the colour_rgb = 255 \n",
    "            elif middle_rgb_value == \"blue\":                                                                   #if the middle_rgb_value is a \"blue\" pixel, then:\n",
    "                colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 255 \n",
    "        if sorted_rgb_dictionary.get(lowest_rgb_value) < 255/2:                                                #if the lowest pixel value is lower than the mid-point, then:\n",
    "            if lowest_rgb_value == \"red\":                                                                      #if the lowest_rgb_value is a \"red\" pixel, then:\n",
    "                colour_rgb[0] = 0                                                                                  #assign the first element in the colour_rgb = 0 \n",
    "            elif lowest_rgb_value == \"green\":                                                                  #if the lowest_rgb_value is a \"green\" pixel, then:\n",
    "                colour_rgb[1] = 0                                                                                  #assign the second element in the colour_rgb = 0 \n",
    "            elif lowest_rgb_value == \"blue\":                                                                   #if the lowest_rgb_value is a \"blue\" pixel, then:\n",
    "                colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 0 \n",
    "\n",
    "        named_colour = rgb_to_name(colour_rgb)                                                                 #use webcolours library database to convert RGB to HEX and then to colour name in English \n",
    "\n",
    "        \"\"\"\n",
    "        #Debugging\n",
    "        #test = name_to_rgb('cyan') \n",
    "        #print(test)\n",
    "        print(type(highest_rgb_value))\n",
    "        print(lowest_rgb_value, middle_rgb_value, highest_rgb_value)\n",
    "        print(sorted_rgb_dictionary)\n",
    "        print(colour_rgb)\n",
    "        #print(colour, named_colour)\n",
    "        \"\"\"\n",
    "    elif (menu_colour == 2):                                                                        #If input is s:\n",
    "        #-----------------------------------------------------------------------------------------COLOUR IDENTIFICATION - METHOD 2------------------------------------------------------------------------------------------  \n",
    "\n",
    "        hsv_colours = cv2.cvtColor(contour_cropped_proc_img, cv2.COLOR_BGR2HSV)\n",
    "        named_colour = ''\n",
    "        colour_rgb = [0,0,0]\n",
    "        # define range wanted color in HSV\n",
    "        red_mask1, red_mask2 = cv2.inRange(hsv_colours, red_lower1, red_upper1), cv2.inRange(hsv_colours, red_lower2, red_upper2)\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "        green_mask = cv2.inRange(hsv_colours, green_lower, green_upper)\n",
    "        blue_mask = cv2.inRange(hsv_colours, blue_lower, blue_upper) \n",
    "        yellow_mask = cv2.inRange(hsv_colours, yellow_lower, yellow_upper)\n",
    "        black_mask = cv2.inRange(hsv_colours, black_lower, black_upper)\n",
    "        \n",
    "        masks = {\"red\" : red_mask  , \"green\" : green_mask, \"blue\" : blue_mask, \"yellow\": yellow_mask, \"black\" : black_mask}\n",
    "        for n, item_masks in enumerate(masks.values()):\n",
    "            pixels_counter = cv2.countNonZero(item_masks)  \n",
    "            if np.sum(item_masks) > 0 and pixels_counter > 8000: named_colour = str(list(masks.keys())[n]); break \n",
    "            else: named_colour = str(list(masks.keys())[n])\n",
    "\n",
    "    #-------------------------------------------------------------------------------------CONTOUR CROPPED SCALING-----------------------------------------------------------------------------------------\n",
    "    contour_cropped = contour_cropped_analysis_img.copy()   \n",
    "    scale_percent = 200 # percent of original size\n",
    "    dim =  (int(contour_cropped.shape[1] * scale_percent / 100), int(contour_cropped.shape[0] * scale_percent / 100))\n",
    "    contour_cropped_resized = cv2.resize(contour_cropped, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "    #------------------------------------------------------------------------------------CONTOUR CROPPED SHARPENING/BLURRING----------------------------------------------------------------------------------------\n",
    "    contour_cropped_sharpened = sharpen_image(contour_cropped_resized, 0.22, 0)\n",
    "    kernel_size = 5\n",
    "    contour_cropped_blurred = cv2.GaussianBlur(contour_cropped_resized,(kernel_size, kernel_size),0)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------CONTOUR CENTER-----------------------------------------------------------------------------------------------------\n",
    "    center_img, center_x, center_y = find_center(contour_cropped_sharpened)\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    ellipse_cropped = contour_cropped_blurred.copy()\n",
    "    if resolution_input_img[1] > resolution_input_img[0]:\n",
    "        ellipse_cropped = center_shape(ellipse_cropped, 165, 90, frequent_b, frequent_g, frequent_r)\n",
    "    else:\n",
    "        ellipse_cropped = center_shape(ellipse_cropped, 90, 165, frequent_b, frequent_g, frequent_r)\n",
    "\n",
    "    #--------------------------------------------------------------------------------CENTER CROPPED POST-PROCESSING---------------------------------------------------------------------------------------\n",
    "    contours_center, hierarchy_center, canny_center_img = find_contours(ellipse_cropped, \"EXTERNAL\")\n",
    "    features_main_code, titles_main_code, images_main_code = features_extraction(contours_center, hierarchy_center, ellipse_cropped, canny_center_img)\n",
    "    \n",
    "    return features_main_code, named_colour, titles_main_code, images_main_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad324f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------DATASET CREATION AND VALIDATION--------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def dataset_creation(path):\n",
    "    timer_start = time.monotonic()\n",
    "    for filepath in glob.iglob(path):\n",
    "        card_selected = card_type_name(filepath)\n",
    "        features_card, colour_card, titles_folder, images_folder = main_code(filepath, 1)\n",
    "        features_card.insert(0, card_selected)\n",
    "        with open(\"dataset.csv\", \"a\", newline='') as fp:\n",
    "            wr = csv.writer(fp, dialect='excel')\n",
    "            wr.writerow(features_card)\n",
    "    timer_stop = time.monotonic()\n",
    "    timer = str(code_timer(timer_start, timer_stop))\n",
    "    messagebox.showinfo(title='Dataset Creation', message='Operation Complete. The process took: '+timer)\n",
    "\n",
    "\n",
    "def dataset_menu(): \n",
    "    path=askdirectory()\n",
    "    rfc = pickle.load(open(\"randomforest_clf_optimised.p\", \"rb\"))\n",
    "    if glob.glob('dataset.csv'):\n",
    "        if (messagebox.askokcancel('Dataset Creation', 'File already exists. Want to modify?')):\n",
    "            if (messagebox.askyesno('Dataset Creation', 'Press Yes to replace the dataset. \\nPress No to add to the existing dataset.')):  \n",
    "                os.remove('dataset.csv')\n",
    "                dataset_creation(str(path) + '/*.jpg')\n",
    "            else:\n",
    "                dataset_creation(str(path) + '/*.jpg')\n",
    "        else:\n",
    "            messagebox.showinfo('Dataset Creation', 'Operation Cancelled')\n",
    "    else:\n",
    "        dataset_creation(str(path) + '/*.jpg')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------CLASSIFIER TRAINING--------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def classifier_training(dataset):\n",
    "    dataset = pd.read_csv(dataset,header=None)\n",
    "    #display(dataset)\n",
    "    X_train = dataset.iloc[:, 1:] \n",
    "    y_train = dataset.iloc[:, 0]\n",
    "    #display(X)\n",
    "    #display(y)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "    \"\"\"\n",
    "    X_reduced = PCA(n_components=3).fit_transform(X_train)\n",
    "    pca = PCA(4)\n",
    "    pca.fit(X_train)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \"\"\"\n",
    "\n",
    "    timer_start = time.monotonic()\n",
    "    rfc = RandomForestClassifier()\n",
    "    param_random = { \n",
    "        'n_estimators': [100, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n",
    "        'bootstrap': [True, False]}\n",
    "\n",
    "    rfc_random_search = RandomizedSearchCV(estimator = rfc, param_distributions = param_random, \n",
    "                                           n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rfc_random_search.fit(X_train, y_train)\n",
    "    best_random_search = list(rfc_random_search.best_params_.values())\n",
    "    #print(rfc_random_search.best_params_)\n",
    "\n",
    "    param_grid = { \n",
    "        'n_estimators': [int(best_random_search[0]-100), int(best_random_search[0]-50), int(best_random_search[0]-25), int(best_random_search[0]),\n",
    "                                                    int(best_random_search[0]+25), int(best_random_search[0])+50, int(best_random_search[0])+100],\n",
    "        'min_samples_split': [int(best_random_search[1]/3), int(best_random_search[1]/2), int(best_random_search[1]), \n",
    "                                                         int(best_random_search[1]*2), int(best_random_search[1]*3)],\n",
    "        'min_samples_leaf': [best_random_search[2]-1, best_random_search[1], best_random_search[1]+1],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [best_random_search[4]-10, best_random_search[4]-5, best_random_search[4], \n",
    "                                            best_random_search[4]+5, best_random_search[4]+10],\n",
    "        'bootstrap': [best_random_search[5]]}\n",
    "\n",
    "    rfc_grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                                   cv = 5, n_jobs = -1, verbose = 2)\n",
    "    rfc_grid_search.fit(X_train, y_train)\n",
    "    best_grid_search = list(rfc_grid_search.best_params_.values())\n",
    "    #print(rfc_grid_search.best_params_)\n",
    "\n",
    "    rfc_optimised = RandomForestClassifier(n_jobs=-1, bootstrap=best_grid_search[0], max_depth=best_grid_search[1], max_features=best_grid_search[2],\n",
    "                                           min_samples_leaf=best_grid_search[3], min_samples_split=best_grid_search[4], n_estimators=best_grid_search[5])\n",
    "    rfc_optimised.fit(X_train,y_train)\n",
    "    pickle.dump(rfc_optimised, open(\"randomforest_clf_optimised.p\", \"wb\"))\n",
    "\n",
    "    timer_stop = time.monotonic()\n",
    "    timer = str(code_timer(timer_start, timer_stop))       \n",
    "    messagebox.showinfo(title='Classifier Training', message='Operation Complete. The process took: '+timer)\n",
    "\n",
    "def classifier_menu():\n",
    "    if glob.glob('dataset.csv'):\n",
    "        if glob.glob('randomforest_clf_optimised.p'):\n",
    "            if (messagebox.askokcancel('Classifier Training', 'File already exists. \\nPress OK to replace the dataset')):        \n",
    "                classifier_training('./dataset.csv')\n",
    "            else:\n",
    "                messagebox.showinfo('Classifier Training', 'Operation Cancelled')\n",
    "        else:\n",
    "            classifier_training('./dataset.csv')\n",
    "    else:\n",
    "        messagebox.showinfo(title='Classifier Training', message='There is no Dataset CSV available!')\n",
    "               \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------MACHINE LEARNING MODEL - FOLDER LOOP ----------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "def uno_clf_folder_menu(val):\n",
    "    path = askdirectory()\n",
    "    if glob.glob('randomforest_clf_optimised.p'):\n",
    "        no = 0\n",
    "        cards_counter = 0\n",
    "        rfc = pickle.load(open(\"randomforest_clf_optimised.p\", \"rb\"))\n",
    "        for filepath in glob.iglob(str(path) + '/*.jpg'):\n",
    "            cards_counter += 1\n",
    "            card_selected = card_type_name(filepath)\n",
    "            features_card, colour_card, titles_folder, images_folder = main_code(filepath, val)\n",
    "            features_array = (np.array(features_card)).reshape(1, -1)\n",
    "            result = int(rfc.predict(features_array))            \n",
    "            output = (colour_card + ' ' + str(result_processing(result))).upper()\n",
    "            \n",
    "            if card_selected != result:\n",
    "                no += 1\n",
    "\n",
    "            image_input = cv2.imread(filepath)\n",
    "            h,w,c = image_input.shape\n",
    "            cv2.putText(image_input, output, (int(h/2.5), int(w/5)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "            cv2.imshow('Current Image', image_input)    \n",
    "            cv2.waitKey(500)                                    #for 1 second        \n",
    "            cv2.destroyWindow('Current Image')                             #destroy the window\n",
    "            \n",
    "        #print('Counter: ', cards_counter)\n",
    "        #print('Wrong cards: ', no)\n",
    "        percentage = str(100 - (no/cards_counter)*100)\n",
    "        messagebox.showinfo(title='Folder Identification', message='Accuracy: ' + percentage + '%')\n",
    "    else:\n",
    "        messagebox.showinfo(title='Folder Identification', message='There is no Classifier Pickle file available!')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------MACHINE LEARNING MODEL - ONE CARD SELECTED------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------   \n",
    "def uno_clf_menu(val):         \n",
    "    cards_window = Toplevel(root)\n",
    "    panel1, panel2, panel3, panel4, panel5, panel6, panel7, panel8 = None,None,None,None,None,None,None,None\n",
    "    path = askopenfilename() \n",
    "    if len(path) > 0:     \n",
    "        rfc = pickle.load(open(\"randomforest_clf_optimised.p\", \"rb\")) \n",
    "        features_card, colour_card, titles_selected, images_selected = main_code(path, val)\n",
    "        features_array = (np.array(features_card)).reshape(1, -1)\n",
    "        result = int(rfc.predict(features_array))\n",
    "        \n",
    "        resized_img = []\n",
    "        for k, img in enumerate(images_selected):\n",
    "            h, w, c = img.shape\n",
    "            if w > h:\n",
    "                img = cv2.resize(img, (220, 133))\n",
    "                resized_img.append(img)\n",
    "            else:\n",
    "                img = cv2.resize(img, (133, 220))\n",
    "                resized_img.append(img)\n",
    "            \n",
    "        image_input = cv2.imread(path)\n",
    "        image_input = cv2.resize(image_input, (int(image_input.shape[1] * 0.4), int(image_input.shape[0] * 0.4)), interpolation = cv2.INTER_AREA)\n",
    "        image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)                                                    # OpenCV represents images in BGR order; however PIL represents images in RGB order, so we need to swap the channels\n",
    "        image_input = Image.fromarray(image_input)                                                                   # convert the images to PIL format...\n",
    "        image_input = ImageTk.PhotoImage(image_input)                                                                # ...and then to ImageTk format\n",
    "\n",
    "        th_center_value, th_center = cv2.threshold(cv2.cvtColor(resized_img[0], cv2.COLOR_BGR2GRAY),150, 400, cv2.THRESH_BINARY_INV)                              #accurate countours, smoother edges compared to regular binary\n",
    "        kernel_center = np.ones((3, 3), np.uint8)                                                                     #higher kernel = less accurate contours\n",
    "        center_close = cv2.morphologyEx(th_center, cv2.MORPH_CLOSE, kernel_center)   \n",
    "        center_canny = cv2.Canny(center_close, 50, 100)\n",
    "        center_canny = cv2.cvtColor(center_canny, cv2.COLOR_BGR2RGB)\n",
    "        center_canny = Image.fromarray(center_canny)                                                                   # convert the images to PIL format...\n",
    "        center_canny = ImageTk.PhotoImage(center_canny)\n",
    "               \n",
    "        drawn_contour_img = cv2.cvtColor(resized_img[1], cv2.COLOR_BGR2RGB)\n",
    "        drawn_contour_img = Image.fromarray(drawn_contour_img)                                                                   # convert the images to PIL format...\n",
    "        drawn_contour_img = ImageTk.PhotoImage(drawn_contour_img)\n",
    "\n",
    "        shi_tomasi_img = cv2.cvtColor(resized_img[2], cv2.COLOR_BGR2RGB)\n",
    "        shi_tomasi_img = Image.fromarray(shi_tomasi_img)                                                                   # convert the images to PIL format...\n",
    "        shi_tomasi_img = ImageTk.PhotoImage(shi_tomasi_img)\n",
    "\n",
    "        harris_corners_img = cv2.cvtColor(resized_img[3], cv2.COLOR_BGR2RGB)\n",
    "        harris_corners_img = Image.fromarray(harris_corners_img)                                                                   # convert the images to PIL format...\n",
    "        harris_corners_img = ImageTk.PhotoImage(harris_corners_img)\n",
    "\n",
    "        houghcircles_img = cv2.cvtColor(resized_img[4], cv2.COLOR_BGR2RGB)\n",
    "        houghcircles_img = Image.fromarray(houghcircles_img)                                                                   # convert the images to PIL format...\n",
    "        houghcircles_img = ImageTk.PhotoImage(houghcircles_img)\n",
    "\n",
    "        children_found_img = cv2.cvtColor(resized_img[5], cv2.COLOR_BGR2RGB)\n",
    "        children_found_img = Image.fromarray(children_found_img)                                                                   # convert the images to PIL format...\n",
    "        children_found_img = ImageTk.PhotoImage(children_found_img)\n",
    "\n",
    "        lines_found_image = cv2.cvtColor(resized_img[6], cv2.COLOR_BGR2RGB)\n",
    "        lines_found_image = Image.fromarray(lines_found_image)                                                                   # convert the images to PIL format...\n",
    "        lines_found_image = ImageTk.PhotoImage(lines_found_image)\n",
    "\n",
    "\n",
    "        # the first panel will store our original image\n",
    "        panel1 = Label(cards_window, image=image_input)\n",
    "        panel1.image = image_input\n",
    "        panel1.pack(side=\"left\", padx=10, pady=10)\n",
    "        # while the second panel will store the edge map\n",
    "        \n",
    "        panel2 = Label(cards_window, image=center_canny)\n",
    "        panel2.image = center_canny\n",
    "        panel2.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel3 = Label(cards_window, image=drawn_contour_img)\n",
    "        panel3.image = drawn_contour_img\n",
    "        panel3.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel4 = Label(cards_window, image=shi_tomasi_img)\n",
    "        panel4.image = shi_tomasi_img\n",
    "        panel4.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel5 = Label(cards_window, image=harris_corners_img)\n",
    "        panel5.image = harris_corners_img\n",
    "        panel5.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel6 = Label(cards_window, image=houghcircles_img)\n",
    "        panel6.image = houghcircles_img\n",
    "        panel6.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel7 = Label(cards_window, image=children_found_img)\n",
    "        panel7.image = children_found_img\n",
    "        panel7.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "        panel8 = Label(cards_window, image=lines_found_image)\n",
    "        panel8.image = lines_found_image\n",
    "        panel8.pack(side=\"right\", padx=10, pady=10)\n",
    "        \n",
    "        messagebox.showinfo(title='RESULT', message= (colour_card.upper() + ' ' + str(result_processing(result))).upper())\n",
    "\n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------CAMERA STREAM--------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def camera_stream():\n",
    "# --------------------------------------------------------------------------------------------CAMERA SETUP-------------------------------------------------------------------------------------------\n",
    "    camera = cv2.VideoCapture(0)                                                                           #setting camera 0 as our image input\n",
    "    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 800)                                                              #setting camera width resolution as 800\n",
    "    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)                                                             #setting camera height resolution as 480\n",
    "    camera.set(cv2.CAP_PROP_FPS, 30)                                                                       #limit camera fps for better performance  \n",
    "    area_sensitivity = 9000 - sensitivity.get()                                                            #area threshold to detect items influenced by the sensitivity slider from the interface\n",
    "    \n",
    "    while True:                                                                                            #create a while loop to check for camera input\n",
    "        rfc = pickle.load(open(\"randomforest_clf_optimised.p\", \"rb\")) \n",
    "        _, frame = camera.read()        \n",
    "        #frame = cv2.flip(frame,1)\n",
    "        hsvframe = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)                                                  #convert the colour space from BGR to HSV for further processing\n",
    "        kernel = np.ones((5,5), \"uint8\")                                                                   #create a kernel to be used for dilation in order to remove noise/holes from the frame\n",
    "\n",
    "#----------------------------------------------------------------------------------------RED COLOUR PROCESSING-------------------------------------------------------------------------------------\n",
    "        red_mask_camera = cv2.inRange(hsvframe, red_lower2, red_upper2)\n",
    "        red_mask_camera = cv2.dilate(red_mask_camera, kernel)                                                    #dilate the red mask and remove the noise by using the kernel\n",
    "        res_red = cv2.bitwise_and(frame, frame, mask = red_mask_camera)                                           #merge the frames based on the red mask pixel coordinates\n",
    "\n",
    "#----------------------------------------------------------------------------------------GREEN COLOUR PROCESSING-------------------------------------------------------------------------------------   \n",
    "        green_mask_camera = cv2.inRange(hsvframe, green_lower, green_upper)\n",
    "        green_mask_camera = cv2.dilate(green_mask_camera, kernel)                                                        #dilate the red mask and remove the noise by using the kernel\n",
    "        res_green = cv2.bitwise_and(frame, frame, mask = green_mask_camera)                                       #merge the frames based on the red mask pixel coordinates\n",
    "\n",
    "#----------------------------------------------------------------------------------------BLUE COLOUR PROCESSING-------------------------------------------------------------------------------------  \n",
    "        blue_mask_camera = cv2.inRange(hsvframe, blue_lower, blue_upper)\n",
    "        blue_mask_camera = cv2.dilate(blue_mask_camera, kernel)                                                          #dilate the red mask and remove the noise by using the kernel\n",
    "        res_blue = cv2.bitwise_and(frame, frame, mask = blue_mask_camera)                                         #merge the frames based on the red mask pixel coordinates\n",
    "\n",
    "#--------------------------------------------------------------------------------------YELLOW COLOUR PROCESSING-------------------------------------------------------------------------------------   \n",
    "        yellow_mask_camera = cv2.inRange(hsvframe, yellow_lower, yellow_upper)\n",
    "        yellow_mask_camera = cv2.dilate(yellow_mask_camera, kernel)                                                      #dilate the red mask and remove the noise by using the kernel\n",
    "        res_yellow = cv2.bitwise_and(frame, frame, mask = yellow_mask_camera)                                     #merge the frames based on the red mask pixel coordinates    \n",
    "\n",
    "#--------------------------------------------------------------------------------------BLACK COLOUR PROCESSING-------------------------------------------------------------------------------------   \n",
    "        black_mask_camera = cv2.inRange(hsvframe, black_lower, black_upper)\n",
    "        black_mask_camera = cv2.dilate(black_mask_camera, kernel)                                                         #dilate the red mask and remove the noise by using the kernel\n",
    "        res_black = cv2.bitwise_and(frame, frame, mask = black_mask_camera)                                        #merge the frames based on the red mask pixel coordinates    \n",
    "\n",
    "#-----------------------------------------------------------------------------------------MASKS PROCESSING-------------------------------------------------------------------------------------------\n",
    "        masks = [red_mask_camera, green_mask_camera, blue_mask_camera, yellow_mask_camera]#, black_mask_camera]\n",
    "        for n, mask in enumerate(masks):\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)             #find the contours on the mask\n",
    "            for j, cnts in enumerate(contours):                                                             #go through all the contours\n",
    "                area = cv2.contourArea(cnts)                                                                #calculate area of the current contour\n",
    "                if(area > area_sensitivity):                                                                   #if area is higher than area_sensitivity (perfect value for my camera = 8000)   \n",
    "                    try:\n",
    "                        if n == 0: card_name = \"RED \"; text_colour = (0,0,255)\n",
    "                        if n == 1: card_name = \"GREEN \"; text_colour = (0,255,0)\n",
    "                        if n == 2: card_name = \"BLUE \"; text_colour = (255,0,0)\n",
    "                        if n == 3: card_name = \"YELLOW \"; text_colour = (0,255,255)\n",
    "                        if n == 4: card_name = \"BLACK \"; text_colour = (0,0,0)\n",
    "\n",
    "                        x, y, w, h = cv2.boundingRect(cnts)                                                     #find the x,y of origin, width and height of the contour\n",
    "                        processing_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "                        validation = list(processing_frame.shape)\n",
    "                        validation = validation[:-1]\n",
    "                        if validation[0] > validation[1]:\n",
    "                            b,g,r = frame[int((x+w+70)/2), int((y+h+270)/2)]\n",
    "                            center_frame = center_shape(processing_frame, 40, 60, b,g,r) \n",
    "                        else:\n",
    "                            b,g,r = frame[int((y+h+270)/2), int((x+w+70)/2)]\n",
    "                            center_frame = center_shape(processing_frame, 60, 40, b,g,r) \n",
    "\n",
    "                        contours_center, hierarchy_center, canny_center_img = find_contours(center_frame, \"EXTERNAL\")                       \n",
    "                        features_camera, titles_camera, images_camera = features_extraction(contours_center, hierarchy_center, center_frame, canny_center_img)\n",
    "                        features_array = (np.array(features_camera)).reshape(1, -1)\n",
    "                        result = int(rfc.predict(features_array))\n",
    "                        text = (card_name + str(result_processing(result)) + \" UNO CARD\").upper()                                       #if area is higher than area_sensitivity (perfect value for my camera = 8000)    \n",
    "                        \n",
    "                    except (TypeError, IndexError, ZeroDivisionError, cv2.error) as e:\n",
    "                        continue\n",
    "                    cv2.imshow(\"canny_center_img\", canny_center_img)\n",
    "                    frame = cv2.rectangle(frame, (x, y), (x + w, y + h), text_colour, 2)                                                #draw a rectangle around the detected image with the RED colour\n",
    "                    cv2.putText(frame, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX,0.7, text_colour, 2, cv2.LINE_AA)                         #create text \"RED UNO CARD\" at the origin x,y of the detected contour\n",
    "#----------------------------------------------------------------------------------------CAMERA TERMINATION--------------------------------------------------------------------------------------\n",
    "        cv2.imshow(\"UNO Card Detection\", frame)                                                            #show the camera stream in a window called \"UNO Card Detection\"\n",
    "        if cv2.waitKey(10) == ord('q'):                                                                     #if the q key has been pressed then:\n",
    "            camera.release()                                                                                   #release the camera input\n",
    "            cv2.destroyAllWindows()                                                                            #close the window\n",
    "            break                                                                                              #exit the while loop\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2f483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------INTERFACE--------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Create object \n",
    "root = Tk()\n",
    " \n",
    "# Adjust size \n",
    "root.geometry(\"500x280\")\n",
    "\n",
    "# Window Title\n",
    "root.title('COMPUTER VISION - UNO IDENTIFICATION')\n",
    "\n",
    "frameCnt = 58\n",
    "frames = [PhotoImage(file='menu.gif',format = 'gif -index %i' %(i)) for i in range(frameCnt)]\n",
    "def update(ind):\n",
    "    try:\n",
    "        frame = frames[ind]\n",
    "        ind += 1\n",
    "        label.configure(image=frame)\n",
    "        root.after(80, update, ind)\n",
    "    except IndexError:\n",
    "        pass\n",
    "      \n",
    "def identification_menu():\n",
    "    def switchwindow():\n",
    "        identification_window.destroy()\n",
    "        root.update()\n",
    "        root.deiconify()\n",
    "        \n",
    "    identification_window = Toplevel(root, height=350, width=125, bg=\"black\", bd=10)\n",
    "    root.withdraw()\n",
    "    \n",
    "    identify_img_opencv_button = Button(identification_window, text = \"IDENTIFY UNO\\nRF CLASSIFIER\\nOPENCV\", bg = \"black\", fg = \"white\", command= lambda: uno_clf_menu(2))\n",
    "    identify_img_opencv_button.place(x=10, y=10)\n",
    "    \n",
    "    identify_img_webclr_button = Button(identification_window, text = \"IDENTIFY UNO\\nRF CLASSIFIER\\nWEBCLR\", bg = \"black\", fg = \"white\", command= lambda: uno_clf_menu(1))\n",
    "    identify_img_webclr_button.place(x=10, y=70)\n",
    "\n",
    "    identify_folder_opencv_button = Button(identification_window, text = \"IDENTIFY UNO\\nFULL FOLDER\\nOPENCV\", bg = \"black\", fg = \"white\", command= lambda: uno_clf_folder_menu(2))\n",
    "    identify_folder_opencv_button.place(x=10, y=130)\n",
    "    \n",
    "    identify_folder_webclr_button = Button(identification_window, text = \"IDENTIFY UNO\\nFULL FOLDER\\nWEBCLR\", bg = \"black\", fg = \"white\", command= lambda: uno_clf_folder_menu(1))\n",
    "    identify_folder_webclr_button.place(x=10, y=190)\n",
    "\n",
    "    identify_camera_button = Button(identification_window, text = \"IDENTIFY UNO\\nCAMERA\", bg = \"black\", fg = \"white\", command=camera_stream)\n",
    "    identify_camera_button.place(x=10, y=250)\n",
    "    \n",
    "    return_button = Button(identification_window, text = \"RETURN\", bg = \"black\", fg = \"red\", command=switchwindow)\n",
    "    return_button.place(x=25, y=305)\n",
    "\n",
    "\n",
    "\n",
    "# Show gif using label\n",
    "label = Label(root)\n",
    "label.place(x = 0,y = 0)\n",
    "\n",
    "# Add text\n",
    "label2 = Label(root, text = \"COMPUTER VISION - UNO IDENTIFICATION\", bg = \"black\", fg = \"white\")\n",
    "label2.pack(pady = 5)\n",
    "\n",
    "#Add slider\n",
    "sensitivity = Scale(root, from_=0, to=5000, orient=HORIZONTAL, bg = \"black\", fg = \"white\", bd = 0, \n",
    "                    label = 'CAMERA SENSITIVITY', troughcolor = \"black\", showvalue = 0, length = 125)\n",
    "sensitivity.place(x=196, y=205)\n",
    "  \n",
    "# Add buttons\n",
    "dataset_button = Button(root, text = \"CREATE CSV DATASET\", bg = \"black\", fg = \"white\", command=dataset_menu)\n",
    "dataset_button.place(x=60, y=250)\n",
    "  \n",
    "train_button = Button(root, text = \"TRAIN RFC CLASSIFIER\", bg = \"black\", fg = \"white\", command=classifier_menu)\n",
    "train_button.place(x=195, y=250)\n",
    "  \n",
    "identify_button = Button(root, text = \"IDENTIFY UNO CARD\", bg = \"black\", fg = \"white\", command=identification_menu)  \n",
    "identify_button.place(x=330, y=250)\n",
    "\n",
    "# Execute tkinter\n",
    "root.after(0, update, 0)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
