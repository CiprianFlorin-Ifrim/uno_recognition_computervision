{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d040a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------LIBRARIES--------------------------------------------------------------------------------------------\n",
    "import cv2                                                                                             #import OpenCV2 library for image processing and algorithms\n",
    "import numpy as np                                                                                     #import numpy mathematical library\n",
    "import operator                                                                                        #additional efficient pyhton fucntions \n",
    "import matplotlib.pyplot as plt                                                                        #import matplotlib library for plotting\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'                 #\n",
    "from scipy import ndimage                                                                              #package contains various functions for multidimensional image processing                       \n",
    "from webcolors import rgb_to_name, name_to_rgb                                                         #import the webcolors library which enables RGB to name and vice versa conversions\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                  #change width of Jupyer Notebook to use the whole window resolution available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdfe520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------DEFINITIONS-------------------------------------------------------------------------------------------\n",
    "def map_value(value, in_low, in_high, out_low, out_high):                                              #create Arduino map() function in python for usage throughout the code\n",
    "    return out_low + (out_high - out_low) * ((value - in_low) / (in_high - in_low))                      #scale input lowest,input highest range to output lowest,output highest range then return\n",
    "\n",
    "def digit_recognition(image):\n",
    "    outcome = pytesseract.image_to_string(image,                                                       #use Pytesseract Engine to identify digits, convert output to integer\n",
    "                         config='--psm 13 --oem 3 -c tessedit_char_whitelist=0123456789')              #load digit model and whitelist characters from 0 to 9 for identification\n",
    "    return outcome                                                                                         #return recognized digit as string, or empty string if nothing has been recognized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad768a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 136\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------IMAGE PRE-PROCESSING---------------------------------------------------------------------------------------\n",
    "colour_img = cv2.imread('./uno_images/b0.jpg')\n",
    "rotated_img = ndimage.rotate(colour_img, -90)                                                          #rotate image by 90 degrees, increase user ease of use\n",
    "rotated_img_copy = rotated_img.copy()                                                                  #create a copy of the rotated_img so that they don't share the same memory address\n",
    "bw_img = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2GRAY)                                                 #convert to a black and white image\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------BINARISATION-------------------------------------------------------------------------------------------\n",
    "#img_sm = cv2.blur(img, (1, 1))                                                                        #not required for the images provided, no changes can be noted        \n",
    "#thr_value, img_th = cv2.threshold(bw_img,150, 400, cv2.THRESH_BINARY)                                 #accurate countours, seems to require more antialising\n",
    "thr_value, th_img = cv2.threshold(bw_img,150, 400, cv2.THRESH_BINARY_INV)                              #accurate countours, smoother edges compared to regular binary\n",
    "#thr_value, img_th = cv2.threshold(bw_img,150, 400, cv2.THRESH_TRUNC)                                  #accurate canny that identifies depth, wrong contours\n",
    "#thr_value, img_th = cv2.threshold(bw_img,150, 400, cv2.THRESH_TOZERO)                                 #accurate canny with noise, issues with contours\n",
    "#thr_value, img_th = cv2.threshold(bw_img,50, 100, cv2.THRESH_TOZERO_INV)                              #inaccurate countours \n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------MORPHOLOGY CORRECTION---------------------------------------------------------------------------------------\n",
    "#very small changes with images provided, helps with countour accuracy\n",
    "kernel = np.ones((3, 3), np.uint8)                                                                     #higher kernel = less accurate contours\n",
    "#close_img = cv2.morphologyEx(img_th, cv2.MORPH_CLOSE, kernel)                                         #erosion + dilute method (internal spaces removal)\n",
    "open_img = cv2.morphologyEx(th_img, cv2.MORPH_OPEN, kernel)                                            #dilute + erosion method (noise removal)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------EDGE DETENCTION & CONTOUR MAPPING---------------------------------------------------------------------------------\n",
    "canny_img = cv2.Canny(open_img, 50, 100)                                                               #edge detection using the OpenCV Canny method\n",
    "contours, _ = cv2.findContours(open_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  \n",
    "selected_contour = 1                                                                                   #0 = frame; 1 = uno card perimeter;\n",
    "contours_img = cv2.drawContours(rotated_img, contours, selected_contour, (0,255,0), 2, cv2.LINE_AA)    #draw selected contour on top of the rotated colour image\n",
    "#print(len(contours))                                                                                  #debugging: show how many contours have been found\n",
    "#print(hierarchy)                                                                                      #debugging: show hierarchy list for all contours\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------MANUAL CONTOUR CROPPING USING MAX FUNCTION-----------------------------------------------------------------------------\n",
    "#max_coords = max((contours[selected_contour]).tolist())\n",
    "#contour_x = (max_coords[0])[0]\n",
    "#contour_y = (max_coords[0])[1]\n",
    "#print(contours[selected_contour])\n",
    "#print(max_coords)\n",
    "#print(contour_x)\n",
    "#print(contour_y)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------OPEN CV CONTOUR CROPPING USING CONTOURS FUNCTION--------------------------------------------------------------------------- \n",
    "x_cnt,y_cnt,w_cnt,h_cnt = cv2.boundingRect(contours[selected_contour])                                 #find origin, width and heigth of image based on selected_contour\n",
    "contour_cropped_proc_img = rotated_img[y_cnt:y_cnt+h_cnt, x_cnt:x_cnt+w_cnt]                           #crop the image based on the coordinates found for processing\n",
    "framed_img = cv2.copyMakeBorder(contour_cropped_proc_img,                                              #add a 30px wide black frame around the cropped image (helps with text placement) \n",
    "                                30,30,30,30,\n",
    "                                cv2.BORDER_CONSTANT,\n",
    "                                value=(0,0,0)) \n",
    "#print(x_cnt, y_cnt, w_cnt, h_cnt)                                                                     #print 4 values for debugging\n",
    " \n",
    "\n",
    "#--------------------------------------------------------------------------------------------COLOUR ANALYSIS------------------------------------------------------------------------------------------- \n",
    "contour_cropped_analysis_img = rotated_img_copy[y_cnt:y_cnt+h_cnt, x_cnt:x_cnt+w_cnt]                  #crop the rotated original image copy with the uno card contour for pattern/colour processing\n",
    "#a patch of pixels is chosen to increase accuracy \n",
    "#as well as optimise the code by running through less pixels in the functions to follow\n",
    "colour_patch_img = contour_cropped_analysis_img[40:80, 100:140]                                        #select a constant patch from the uno card image to perform the pixel analysis\n",
    "bgr_pixels = colour_patch_img.tolist()                                                                 #transform patch array to list containing bgr tuples\n",
    "#print(bgr_pixels)\n",
    "b = [x[0][0] for x in bgr_pixels]                                                                      #extract blue values from bgr list\n",
    "g = [x[0][1] for x in bgr_pixels]                                                                      #extract green values from bgr list\n",
    "r = [x[0][2] for x in bgr_pixels]                                                                      #extract red values from bgr list\n",
    "frequent_b = (max(set(b), key = b.count))                                                              #find the most frequent blue value in the image patch selected\n",
    "frequent_g = (max(set(g), key = g.count))                                                              #find the most frequent green value in the image patch selected\n",
    "frequent_r = (max(set(r), key = r.count))                                                              #find the most frequent red value in the image patch selected\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------COLOUR IDENTIFICATION------------------------------------------------------------------------------------------    \n",
    "rgb_dictionary = {\"red\": frequent_r, \"green\": frequent_g, \"blue\": frequent_b}                          #create dictionary containing the RGB colour space, and assign most frequent value from patch\n",
    "sorted_rgb_dictionary = dict((y, x) for y, x in sorted(rgb_dictionary.items(),                         #sort dictionary based on value, not key and since the output is a tuple, transform to dictionary\n",
    "                                                       key=operator.itemgetter(1)))                    #choose value for sorting process, (1) = value, (0) = key\n",
    "highest_rgb_value = list(sorted_rgb_dictionary)[2]                                                     #extract highest value whether it is a blue, green or red pixel (key)\n",
    "middle_rgb_value = list(sorted_rgb_dictionary)[1]                                                      #extract middle value whether it is a blue, green or red pixel (key)\n",
    "lowest_rgb_value = list(sorted_rgb_dictionary)[0]                                                      #extract lowest value whether it is a blue, green or red pixel (key)\n",
    "\n",
    "#the following part of the code changes the R,G,B values of the pixels to an extreme\n",
    "#this helps identify the colour correctly with different levels of brightness in the image\n",
    "colour_rgb = [0,0,0]                                                                                   #create list to store the new RGB values for colour identification\n",
    "if sorted_rgb_dictionary.get(highest_rgb_value) >= 255/2:                                              #if the highest pixel value is higher than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "elif sorted_rgb_dictionary.get(highest_rgb_value) <= 255/2:                                            #if the highest pixel value is lower than the mid-point, then:\n",
    "    if highest_rgb_value == \"red\":                                                                     #if the highest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 128                                                                                #assign the first element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"green\":                                                                 #if the highest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 128                                                                                #assign the second element in the colour_rgb = 128 \n",
    "    elif highest_rgb_value == \"blue\":                                                                  #if the highest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 128                                                                                #assign the third element in the colour_rgb = 128 \n",
    "if sorted_rgb_dictionary.get(middle_rgb_value) > 150:                                                  #if the middle pixel value is higher than 150, then:\n",
    "    if middle_rgb_value == \"red\":                                                                      #if the middle_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 255                                                                                #assign the first element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"green\":                                                                  #if the middle_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 255                                                                                #assign the second element in the colour_rgb = 255 \n",
    "    elif middle_rgb_value == \"blue\":                                                                   #if the middle_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 255                                                                                #assign the third element in the colour_rgb = 255 \n",
    "if sorted_rgb_dictionary.get(lowest_rgb_value) < 255/2:                                                #if the lowest pixel value is lower than the mid-point, then:\n",
    "    if lowest_rgb_value == \"red\":                                                                      #if the lowest_rgb_value is a \"red\" pixel, then:\n",
    "        colour_rgb[0] = 0                                                                                  #assign the first element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"green\":                                                                  #if the lowest_rgb_value is a \"green\" pixel, then:\n",
    "        colour_rgb[1] = 0                                                                                  #assign the second element in the colour_rgb = 0 \n",
    "    elif lowest_rgb_value == \"blue\":                                                                   #if the lowest_rgb_value is a \"blue\" pixel, then:\n",
    "        colour_rgb[2] = 0                                                                                  #assign the third element in the colour_rgb = 0 \n",
    "        \n",
    "named_colour = rgb_to_name(colour_rgb)                                                                 #use webcolours library database to convert RGB to HEX and then to colour name in English \n",
    "colour_framed_img = cv2.copyMakeBorder(framed_img,7,7,7,7,cv2.BORDER_CONSTANT,                         #add a 7px wide frame at the edge of the frame with the same colour as the UNO card\n",
    "                                       value=(colour_rgb[2],colour_rgb[1],colour_rgb[0]))              #elements 2,1,0 used because of BGR output, and RGB input\n",
    "#Debugging\n",
    "#test = name_to_rgb('cyan') \n",
    "#print(test)\n",
    "#print(sorted_rgb_dictionary)\n",
    "#print(type(highest_rgb_value))\n",
    "#print(lowest_rgb_value, middle_rgb_value, highest_rgb_value)\n",
    "#print(colour, named_colour)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------DIGIT RECOGNITION---------------------------------------------------------------------------------------------\n",
    "#normalize resolution between all images \n",
    "contour_cropped_copy = contour_cropped_analysis_img.copy()                                             #create a copy of the uno card contour cropped image\n",
    "normalize_resolution = (300, 450)                                                                      #have a set resolution between all images (after cropping)\n",
    "normalized_img = cv2.resize(contour_cropped_copy, normalize_resolution,                                #set image to be resized and the resolution\n",
    "                                        interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "#center cropping for digit extraction\n",
    "max_coords = max((normalized_img).tolist())                                                            #find the the highest coordinates x and y of the right bottom corner pixel\n",
    "coord_x = (max_coords[0])[0]                                                                           #extract x coordinate from list\n",
    "coord_y = (max_coords[0])[1]                                                                           #extract y coordinate from list\n",
    "center_cropped_img =  normalized_img[int(coord_x*0.9):                                                 #crop the image in the center based on the coordinates found + alternation\n",
    "                                           int(coord_x*2.4), int(coord_y/1.7):\n",
    "                                           int(coord_y*1.6)]\n",
    "print(coord_x, coord_y)                                                                                #print x and y coordiantes for debugging\n",
    "\n",
    "#cropped image scaling for ease of use\n",
    "scale = 250                                                                                            #percent of original size for scaling, 250%\n",
    "dim = int(center_cropped_img.shape[1]*scale/100),int(center_cropped_img.shape[0]*scale/100)            #create variable storing the new resolution for scaling based on percentage\n",
    "rescaled_img = cv2.resize(center_cropped_img, dim, interpolation = cv2.INTER_AREA)                     #rescale the center cropped image so that it is 2.5 times bigger (ease of use)\n",
    "\n",
    "#image post-processing\n",
    "rescaled_img_bw = cv2.cvtColor(rescaled_img, cv2.COLOR_BGR2GRAY)                                       #convert rescaled center image to black and white channels for post-processing\n",
    "thr_value2, th_digit_img = cv2.threshold(rescaled_img_bw,150, 400, cv2.THRESH_BINARY_INV)              #accurate countours, smoother edges compared to regular binary\n",
    "kernel_close = np.ones((3, 3), np.uint8)                                                               #higher kernel = less accurate contours\n",
    "morph_digit_img = cv2.morphologyEx(th_digit_img, cv2.MORPH_CLOSE, kernel_close)                        #erosion + dilute method (internal spaces removal)\n",
    "\n",
    "#contour extraction\n",
    "contours_digits, hierarchy_digits = cv2.findContours(morph_digit_img,                                  #chosen image\n",
    "                                                     cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)             #contour points precision\n",
    "drawn_contours_img = cv2.drawContours(rescaled_img, contours_digits, 2, (0,255,0), 2, cv2.LINE_AA)     #draw contour 1 = frame; 2 = uno card digit;\n",
    "\n",
    "#image digit identification\n",
    "try:                                                                                                   #check for code errors when calling the definition\n",
    "    digit = int(digit_recognition(morph_digit_img))                                                    #in the conversion of the string to int (once digit has been recognized)\n",
    "except ValueError:                                                                                     #returns \"ValueError\" when the digit has not been recognized = empty string = conversion error\n",
    "    try:                                                                                               #check for errors again when running the following commands: \n",
    "        vertical_flipped_morph_digit_img = cv2.flip(morph_digit_img,0)                                 #flip the digit detection(after morphology) image vertically \n",
    "        colour_framed_img = cv2.flip(colour_framed_img,0)                                              #also vertically flip the output final image for user ease of use\n",
    "        digit = int(digit_recognition(vertical_flipped_morph_digit_img))                               #do the conversion again, if no error\n",
    "        pass                                                                                           #pass\n",
    "    except ValueError:\n",
    "        horizontal_flipped_morph_digit_img = cv2.flip(vertical_flipped_morph_digit_img,1)              #flip the digit detection image, with a vertical flip, horizontally for full correct alignment\n",
    "        colour_framed_img = cv2.flip(colour_framed_img,1)                                              #also vertically flip the output final image for user ease of use\n",
    "        digit = int(digit_recognition(horizontal_flipped_morph_digit_img))                             #do the conversion again, if no error\n",
    "\n",
    "digit_name = \"\"                                                                                        #create empty string storing the digit english name\n",
    "if (digit) == 0:                                                                                       #if the digit identified is 0, then: \n",
    "    digit_name = \"zero\"                                                                                #assign to empty string the text \"zero\"\n",
    "elif (digit) == 1:                                                                                     #if the digit identified is 1, then: \n",
    "    digit_name = \"one\"                                                                                 #assign to empty string the text \"one\"\n",
    "elif (digit) == 2:                                                                                     #if the digit identified is 2, then: \n",
    "    digit_name = \"two\"                                                                                     #assign to empty string the text \"two\"\n",
    "elif (digit) == 3:                                                                                     #if the digit identified is 3, then: \n",
    "    digit_name = \"three\"                                                                                   #assign to empty string the text \"three\"\n",
    "elif (digit) == 4:                                                                                     #if the digit identified is 4, then: \n",
    "    digit_name = \"four\"                                                                                    #assign to empty string the text \"four\"\n",
    "elif (digit) == 5:                                                                                     #if the digit identified is 5, then: \n",
    "    digit_name = \"five\"                                                                                    #assign to empty string the text \"five\"\n",
    "elif (digit) == 6:                                                                                     #if the digit identified is 6, then:  \n",
    "    digit_name = \"six\"                                                                                     #assign to empty string the text \"six\"\n",
    "elif (digit) == 7:                                                                                     #if the digit identified is 7, then: \n",
    "    digit_name = \"seven\"                                                                                   #assign to empty string the text \"seven\"\n",
    "elif (digit) == 8:                                                                                     #if the digit identified is 8, then: \n",
    "    digit_name = \"eight\"                                                                                   #assign to empty string the text \"eight\"\n",
    "elif (digit) == 9:                                                                                     #if the digit identified is 8, then: \n",
    "    digit_name = \"nine\"                                                                                    #assign to empty string the text \"nine\"\n",
    "    \n",
    "#print(type(digit), digit)                                                                             #print the type of the variable and its contents\n",
    "#print(digit_name)                                                                                     #print string to check correct output\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------------------------IDENTIFICATION TEXT PLACEMENT--------------------------------------------------------------------------------------                                                                      \n",
    "disp_x = +240                                                                                          #perfect value = +240\n",
    "disp_y = -165                                                                                          #perfect value = -165\n",
    "text_displayed = (named_colour + \" \" + digit_name + \" uno card\").upper()\n",
    "identified_img = cv2.putText(colour_framed_img,                                                        #create text on top of image\n",
    "                             text_displayed,                                                           #set text to text_displayed string\n",
    "                             (y_cnt+disp_y, x_cnt+disp_x),                                             #set coords to contour bottom right corner with displacement\n",
    "                             cv2.FONT_HERSHEY_SIMPLEX,                                                 #set OpenCV font\n",
    "                             0.4, (0,255,0), 1, cv2.LINE_AA)                                           #font size, colour, thickness, antialiasing on the text for smoother edges\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------POST-PROCESSING IMAGE SCALLING-------------------------------------------------------------------------------------                                                                                             \n",
    "scaling = int(identified_img.shape[1]*1.5),int(identified_img.shape[0]*1.5)                            #scale the output image by 1.5x\n",
    "final_img = cv2.resize(identified_img, scaling, interpolation = cv2.INTER_AREA)                        #scale the identified_img, with scaling resolution\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------IMAGE DISPLAY--------------------------------------------------------------------------------------------- \n",
    "cv2.imshow('original', colour_img)                                                                     #show the original image to the user\n",
    "cv2.imshow('cropped', contour_cropped_analysis_img)                                                    #show the contour cropped image to the user\n",
    "cv2.imshow('final_img', final_img)                                                                     #show the final image to the user\n",
    "\n",
    "\"\"\"\n",
    "#Debugging digit extraction\n",
    "cv2.imshow('rez_normalized',normalized_img)\n",
    "cv2.imshow('rescaled',rescaled_img)\n",
    "cv2.imshow('cropped',morph_digit_img)\n",
    "cv2.imshow('th',th_img)\n",
    "cv2.imshow('contours',drawn_contours_img)\n",
    "\"\"\"\n",
    "\n",
    "key = cv2.waitKey(0)                                                                                   #wait for any key press\n",
    "cv2.destroyAllWindows()                                                                                #close all windows displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f70d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
